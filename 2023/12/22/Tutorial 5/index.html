<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>Pytorch Tutorial 5 - Hexo</title><link rel="manifest" href="/blog/manifest.json"><meta name="application-name" content="Quansui&#039;s Blog"><meta name="msapplication-TileImage" content="/my_img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Quansui&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="The reason use the NN is inner kernel of logistic regression is still linear, to avoid the linear relationship, the NN can use activation function, for instance ReLU. In this case, we use ReLu as our"><meta property="og:type" content="blog"><meta property="og:title" content="Pytorch Tutorial 5"><meta property="og:url" content="https://zjsygqs398.github.io/blog/2023/12/22/Tutorial%205/"><meta property="og:site_name" content="Hexo"><meta property="og:description" content="The reason use the NN is inner kernel of logistic regression is still linear, to avoid the linear relationship, the NN can use activation function, for instance ReLU. In this case, we use ReLu as our"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://zjsygqs398.github.io/blog/img/og_image.png"><meta property="article:published_time" content="2023-12-21T21:06:08.000Z"><meta property="article:modified_time" content="2024-06-20T01:29:14.729Z"><meta property="article:author" content="John Doe"><meta property="article:tag" content="Python"><meta property="article:tag" content="Pytorch"><meta property="article:tag" content="Machine Learning"><meta property="article:tag" content="Deep Learning"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://zjsygqs398.github.io/blog/img/og_image.png"><meta property="fb:app_id"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://zjsygqs398.github.io/blog/2023/12/22/Tutorial%205/"},"headline":"Pytorch Tutorial 5","image":["https://zjsygqs398.github.io/blog/img/og_image.png"],"datePublished":"2023-12-21T21:06:08.000Z","dateModified":"2024-06-20T01:29:14.729Z","author":{"@type":"Person","name":"John Doe"},"publisher":{"@type":"Organization","name":"Hexo","logo":{"@type":"ImageObject","url":"https://zjsygqs398.github.io/my_img/logo.svg"}},"description":"The reason use the NN is inner kernel of logistic regression is still linear, to avoid the linear relationship, the NN can use activation function, for instance ReLU. In this case, we use ReLu as our"}</script><link rel="canonical" href="https://zjsygqs398.github.io/blog/2023/12/22/Tutorial%205/"><link rel="icon" href="/blog/my_img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/blog/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.0.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/blog/"><img src="/blog/my_img/logo.svg" alt="Hexo" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/blog/">Home</a><a class="navbar-item" href="/blog/archives">Archives</a><a class="navbar-item" href="/blog/categories">Categories</a><a class="navbar-item" href="/blog/tags">Tags</a><a class="navbar-item" target="_blank" rel="noopener" href="https://github.com/zjsygqs398">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/zjsygqs398"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-12-21T21:06:08.000Z" title="12/22/2023, 8:06:08 AM">2023-12-22</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-06-20T01:29:14.729Z" title="6/20/2024, 11:29:14 AM">2024-06-20</time></span><span class="level-item"><a class="link-muted" href="/blog/categories/Pytorch-Introduction/">Pytorch Introduction</a></span></div></div><h1 class="title is-3 is-size-4-mobile">Pytorch Tutorial 5</h1><div class="content"><p>The reason use the NN is inner kernel of logistic regression is still linear, to avoid the linear relationship, the NN can use activation function, for instance ReLU.</p>
<p>In this case, we use ReLu as our activation function to predict the image, and it can be found that the accuracy is far better than LR, shows more abilities.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> os <span class="keyword">import</span> path, mkdir</span><br><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> randint</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> torchvision.datasets <span class="keyword">import</span> MNIST</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> ToTensor</span><br><span class="line"><span class="keyword">from</span> torch.utils.data.sampler <span class="keyword">import</span> SubsetRandomSampler</span><br><span class="line"><span class="keyword">from</span> torch.utils.data.dataloader <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">dataset = MNIST(root=<span class="string">&quot;./data&quot;</span>, download=<span class="literal">True</span>, transform=ToTensor())</span><br><span class="line">test_dataset = MNIST(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">False</span>, transform=ToTensor())</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">split_indices</span>(<span class="params">n, rate</span>):</span><br><span class="line">    <span class="comment"># create number of validation set</span></span><br><span class="line">    n_val = <span class="built_in">int</span>(n * rate)</span><br><span class="line">    <span class="comment"># create shuffled index from 0-n, with no repeat</span></span><br><span class="line">    idxs = np.random.permutation(n)</span><br><span class="line">    <span class="comment"># retuen (n_val,last) index and (first n_val) index</span></span><br><span class="line">    <span class="comment"># i.e. training index and validation index</span></span><br><span class="line">    <span class="keyword">return</span> idxs[n_val:], idxs[:n_val]</span><br><span class="line"></span><br><span class="line">train_indices, val_indices = split_indices(<span class="built_in">len</span>(dataset), <span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line">train_sampler = SubsetRandomSampler(train_indices)</span><br><span class="line">train_loder = DataLoader(dataset,</span><br><span class="line">                         batch_size,</span><br><span class="line">                         sampler=train_sampler)</span><br><span class="line"></span><br><span class="line">val_sampler = SubsetRandomSampler(val_indices)</span><br><span class="line">val_loder = DataLoader(dataset,</span><br><span class="line">                       batch_size,</span><br><span class="line">                       sampler=val_sampler)</span><br><span class="line"></span><br><span class="line">input_size = <span class="number">28</span> * <span class="number">28</span></span><br><span class="line">num_classes = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MnistModel</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_size, hidden_size, out_size</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        self.linear1 = nn.Linear(in_size, hidden_size)</span><br><span class="line"></span><br><span class="line">        self.linear2 = nn.Linear(hidden_size, out_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, xb</span>):</span><br><span class="line">        <span class="comment"># flatten</span></span><br><span class="line">        xb = xb.view(xb.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># xb = xb.reshape(xb.size(0), -1)</span></span><br><span class="line">        <span class="keyword">return</span> self.linear2(F.relu(self.linear1(xb)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># for t in model.parameters():</span></span><br><span class="line"><span class="comment">#     print(t.shape)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># for img, labels in train_loder:</span></span><br><span class="line"><span class="comment">#     outputs = model(img)</span></span><br><span class="line"><span class="comment">#     loss = F.cross_entropy(outputs, labels)</span></span><br><span class="line"><span class="comment">#     break</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_device</span>():</span><br><span class="line">    <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">        <span class="keyword">return</span> torch.device(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> torch.device(<span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">to_device</span>(<span class="params">data, device</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(data, (<span class="built_in">list</span>, <span class="built_in">tuple</span>)):</span><br><span class="line">        <span class="keyword">return</span> [to_device(x, device) <span class="keyword">for</span> x <span class="keyword">in</span> data]</span><br><span class="line">    <span class="keyword">return</span> data.to(device, non_blocking=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># for img, label in train_loder:</span></span><br><span class="line"><span class="comment">#     print(img.shape)</span></span><br><span class="line"><span class="comment">#     img = to_device(img, device)</span></span><br><span class="line"><span class="comment">#     print(img.device)</span></span><br><span class="line"><span class="comment">#     break</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DeviceDataLoder</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dl, device</span>):</span><br><span class="line">        self.dl = dl</span><br><span class="line">        self.device = device</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># lazy load here</span></span><br><span class="line">        <span class="comment"># instead of load data into device each time, instead, load each batch</span></span><br><span class="line">        <span class="keyword">for</span> b <span class="keyword">in</span> self.dl:</span><br><span class="line">            <span class="keyword">yield</span> to_device(b, self.device)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.dl)</span><br><span class="line"></span><br><span class="line"><span class="comment"># use DeviceDataLoader as warpper</span></span><br><span class="line">train_dl = DeviceDataLoder(train_loder, get_device())</span><br><span class="line">valid_dl = DeviceDataLoder(val_loder, get_device())</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss_batch</span>(<span class="params">model, loss_func, xb, yb, opt=<span class="literal">None</span>, metric=<span class="literal">None</span></span>):</span><br><span class="line">    preds = model(xb)</span><br><span class="line"></span><br><span class="line">    loss = loss_func(preds, yb)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> opt <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        loss.backward()</span><br><span class="line">        opt.step()</span><br><span class="line">        opt.zero_grad()</span><br><span class="line"></span><br><span class="line">    metric_result = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> metric <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        metric_result = metric(preds, yb)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss.item(), <span class="built_in">len</span>(xb), metric_result</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">model, loss_func, valid_dl, metric=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        results = [loss_batch(model, loss_func, xb, yb, metric=metric)</span><br><span class="line">                   <span class="keyword">for</span> xb, yb <span class="keyword">in</span> valid_dl]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># separate the lists</span></span><br><span class="line">        loss, nums, metric = <span class="built_in">zip</span>(*results)</span><br><span class="line">        total = np.<span class="built_in">sum</span>(nums)</span><br><span class="line">        avg_loss = np.<span class="built_in">sum</span>(np.multiply(loss, nums)) / total</span><br><span class="line">        avg_metric = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> metric <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            avg_metric = np.<span class="built_in">sum</span>(np.multiply(metric, nums)) / total</span><br><span class="line">    <span class="keyword">return</span> avg_loss, total, avg_metric</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">epochs, lr, model, loss_func, train_dl, valid_dl, opt_fn=<span class="literal">None</span>, metric=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">if</span> opt_fn <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        opt_fn = torch.optim.SGD</span><br><span class="line">    opt = opt_fn(model.parameters(), lr=lr)</span><br><span class="line">    loss_history = []</span><br><span class="line">    metric_history = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        <span class="keyword">for</span> xb, yb <span class="keyword">in</span> train_dl:</span><br><span class="line">            loss_batch(model, loss_func, xb, yb, opt)</span><br><span class="line">        result = evaluate(model, loss_func, valid_dl, metric)</span><br><span class="line">        val_loss, total, val_metric = result</span><br><span class="line"></span><br><span class="line">        loss_history.append(val_loss)</span><br><span class="line">        metric_history.append(val_metric)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> metric <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;Epoch [<span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;epochs&#125;</span>], Loss: <span class="subst">&#123;val_loss:<span class="number">.4</span>f&#125;</span>, Metric: <span class="subst">&#123;val_metric:<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;Epoch [<span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;epochs&#125;</span>], Loss: <span class="subst">&#123;val_loss:<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss_history, metric_history</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">accuracy</span>(<span class="params">output, label</span>):</span><br><span class="line">    _, preds = torch.<span class="built_in">max</span>(output, dim=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> torch.<span class="built_in">sum</span>(label == preds).item() / <span class="built_in">len</span>(preds)</span><br><span class="line"></span><br><span class="line">model = MnistModel(input_size, <span class="number">32</span>, num_classes)</span><br><span class="line">to_device(model, get_device())</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> path.exists(<span class="string">&#x27;./tutorial5/mnist-logistic.pth&#x27;</span>):</span><br><span class="line">    model.load_state_dict(torch.load(<span class="string">&#x27;./tutorial5/mnist-logistic.pth&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    loss_history, metric_history = fit(<span class="number">5</span>, <span class="number">0.5</span>, model, F.cross_entropy,</span><br><span class="line">                                       train_dl,</span><br><span class="line">                                       valid_dl,</span><br><span class="line">                                       opt_fn=torch.optim.SGD,</span><br><span class="line">                                       metric=accuracy)</span><br><span class="line">    <span class="comment"># it will save the weight and bias for this model</span></span><br><span class="line">    <span class="comment"># new dir</span></span><br><span class="line">    mkdir(<span class="string">&#x27;./tutorial5&#x27;</span>)</span><br><span class="line">    torch.save(model.state_dict(), <span class="string">&#x27;./tutorial5/mnist-logistic.pth&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">prediction_img</span>(<span class="params">img, model</span>):</span><br><span class="line">    xb = img.unsqueeze(<span class="number">0</span>)</span><br><span class="line">    yb = model(xb)</span><br><span class="line">    _, preds = torch.<span class="built_in">max</span>(yb, dim=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> preds[<span class="number">0</span>].item()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    img, label = test_dataset[randint(<span class="number">0</span>, <span class="built_in">len</span>(test_dataset) - <span class="number">1</span>)]</span><br><span class="line">    img_np = np.array(img)</span><br><span class="line">    plt.imshow(img_np.squeeze(), cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">    <span class="built_in">print</span>(prediction_img(img, model))</span><br></pre></td></tr></table></figure></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/blog/tags/Python/">Python</a><a class="link-muted mr-2" rel="tag" href="/blog/tags/Pytorch/">Pytorch</a><a class="link-muted mr-2" rel="tag" href="/blog/tags/Machine-Learning/">Machine Learning</a><a class="link-muted mr-2" rel="tag" href="/blog/tags/Deep-Learning/">Deep Learning</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/blog/2024/06/15/INFO%205992/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">USYD - INFO 5992</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/blog/2023/12/22/Tutorial%203/"><span class="level-item">Pytorch Tutorial 3</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/blog/my_img/avatar.png" alt="Quansui"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Quansui</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Sydney, Australia</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/blog/archives"><p class="title">21</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/blog/categories"><p class="title">3</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/blog/tags"><p class="title">25</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/zjsygqs398" target="_blank" rel="noopener">Follow</a></div></div></div><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/blog/categories/Internship/"><span class="level-start"><span class="level-item">Internship</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/Pytorch-Introduction/"><span class="level-start"><span class="level-item">Pytorch Introduction</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/USYD-Lecture/"><span class="level-start"><span class="level-item">USYD - Lecture</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-06-16T00:12:25.000Z">2024-06-16</time></p><p class="title"><a href="/blog/2024/06/16/COMP%205046/">USYD - COMP 5046</a></p><p class="categories"><a href="/blog/categories/USYD-Lecture/">USYD - Lecture</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-06-16T00:10:20.000Z">2024-06-16</time></p><p class="title"><a href="/blog/2024/06/16/COMP%205329/">USYD - COMP 5329</a></p><p class="categories"><a href="/blog/categories/USYD-Lecture/">USYD - Lecture</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-06-16T00:08:50.000Z">2024-06-16</time></p><p class="title"><a href="/blog/2024/06/16/DATA%205207/">USYD - DATA 5207</a></p><p class="categories"><a href="/blog/categories/USYD-Lecture/">USYD - Lecture</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-06-15T02:10:42.000Z">2024-06-15</time></p><p class="title"><a href="/blog/2024/06/15/INFO%205992/">USYD - INFO 5992</a></p><p class="categories"><a href="/blog/categories/USYD-Lecture/">USYD - Lecture</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-12-21T21:06:08.000Z">2023-12-22</time></p><p class="title"><a href="/blog/2023/12/22/Tutorial%205/">Pytorch Tutorial 5</a></p><p class="categories"><a href="/blog/categories/Pytorch-Introduction/">Pytorch Introduction</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/blog/archives/2024/"><span class="level-start"><span class="level-item">2024</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/blog/archives/2023/"><span class="level-start"><span class="level-item">2023</span></span><span class="level-end"><span class="level-item tag">15</span></span></a></li><li><a class="level is-mobile" href="/blog/archives/2022/"><span class="level-start"><span class="level-item">2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/blog/tags/Cache/"><span class="tag">Cache</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Data-Analyse/"><span class="tag">Data Analyse</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Deep-Learning/"><span class="tag">Deep Learning</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/GIT/"><span class="tag">GIT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/IT-Innovation/"><span class="tag">IT Innovation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/JPA/"><span class="tag">JPA</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Java/"><span class="tag">Java</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Linear-Regression/"><span class="tag">Linear Regression</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/MQ/"><span class="tag">MQ</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Machine-Learning/"><span class="tag">Machine Learning</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/NLP/"><span class="tag">NLP</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Natural-Language-Processing/"><span class="tag">Natural Language Processing</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Python/"><span class="tag">Python</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Pytorch/"><span class="tag">Pytorch</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/R/"><span class="tag">R</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Redis/"><span class="tag">Redis</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Schedule/"><span class="tag">Schedule</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Security/"><span class="tag">Security</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Shiro/"><span class="tag">Shiro</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Social-Science/"><span class="tag">Social Science</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/SpringBoot/"><span class="tag">SpringBoot</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Startups/"><span class="tag">Startups</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Swagger/"><span class="tag">Swagger</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Thread/"><span class="tag">Thread</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Tools/"><span class="tag">Tools</span><span class="tag">2</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/blog/"><img src="/blog/my_img/logo.svg" alt="Hexo" height="28"></a><p class="is-size-7"><span>&copy; 2024 John Doe</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/zjsygqs398"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/blog/js/column.js"></script><script src="/blog/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/blog/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/blog/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/blog/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/blog/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>