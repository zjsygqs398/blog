{"posts":[{"title":"USYD - COMP 5329","text":"COMP 5329Lecture 2P9 XOR P31 Activation P36 CE P37 KL, Entropy P38 SoftMax p36, p37 two attributes cross-entropy loss issue?the disadvantage of batch gradient descent is when N is too large, the computation is very expensive, but the one example SGD only uses the single example. It may not be the best, due to the random. mini-batches SGD: divide into mini-batches, in each epoch calculate the gradient extension content: sensitivity? make the back propagation similar to the feedforward Lecture 3 GDDifferent gradient descent.Challenges: proper lr, same lr, saddle point P9-10 Momentum P11 NAG P17 Adagrad P21 Adadelta P25 RMSprop P26, 27 Adam P34 Initialization Batch Gradient descent: Accuracy Stochastic gradient descent: efficiency Mini-batch gradient descent: trade-off of accuracy and efficiency Momentum is to update SGD, to accelerate and dampen oscillation increase the momentum term in the same direction, reduce in change direction NAG: The big jump in the standard momentum is too aggressive So, in the Nesterov accelerated gradient use a previous gradient to big jump and a correction ![Untitled](./post_img/COMP 5329/Untitled.png) theta - r v_t-1 means that update according to the previous, which is the big jump depending on the previous accumulated gradient. Then, calculate the gradient plus the contributed previously accumulated gradient to update the theta Adagrad: to achieve the different learning rate for features i means dimension t means iteration suitable for sparse data but the global learning rate needed Adadelta: ![Untitled](./post_img/COMP 5329/Untitled%201.png) in order to deal with the problem of Adagrad(infinitesimally small for the denominator in the end), modify the gt equation as above. Contributed the last square sum of gt, and current gt. H is the secondary gradient with consistent units Lecture 4 NormP10 weight decay pls write the structure of the normalization inverted, dropout-connect BN, (reduce covariance) R means regularisation functions, r on page 6 is the upper boundary for parameter complex Page 24 in slide, bottom 2 are independent methods the group right top corner is the normal training process(i.e. only train on the training set) drop out scale down in the training process, each unit has with p possibility p present 1-p disappear in the test process, they always present p is times the w in layer inverted see slide M in slide 36 is the matrix of binary (1 or 0) adding the extra linear function after the normalization in each layer’s output. gamma means the scale parameter, beta means the shift parameter batch norm: norm applies in all examples in this batch in each channel layer norm: norm applies in each data sample in this batch instance norm: norm applies in an example in this batch in a channel group norm: norms apply in some channels in an example (split an example into multiple parts) in a data batch Lecture 5 CNNP46 different sorts of pooling Spectral pooling? un-pooling uses the (max) location information to reverse the process, keeping the 0 at information lacking place more previous layer, the information is more simple. (line, color block) more higher layer, the more meaningful information included transposed convolution is also called the deconvolution method, enlarging the feature map until keeps the same as input size in the process of deconvolution, the output will larger, it will happen to overlap in the process, summation the overlap region. Also, it has the stride, crop (like the padding, but crop the data in the output) Output size = (N-1) S + K - 2C In pytorch, using the sequential in init rather than init function like tut note.the kernel in CNN is similar to the digital, tut 6 notebook its like the mouse in 5318, get a bigger score of the kernel output Lecture 7dead relu means that the zero output of the relu activation function Data augmentation is rotate, distortion, color changing etc. methods to manipulate the data. In local response normalization, a is the center of the region overlapping pooling, polling stride less than pooling kernel size smaller filter means deeper, more non-linearity, fewer parameters. p is changing to ensure the size of the output is same on the googlenet p28, right is the google net structure, and left is the normal way. It helps to decrease the depth of the feature map in the right method. p37 is used to avoid the overconfident of the model, with the label smoothing 1 by 1 conv layer is used to exchange the information among channels ???? Shuffle net is another way to exchange information Extension Ghost filter? Lego filter? adder filter? Lecture 8Lecture 9The masked LM in BERT in used to predict the masked word by linear regression Classification in BERT is used in the binary classifier to identify the 1 or 2 sentences P49 the place of dot product is, output of the classifier and the representation of token, multiple numbers is because the multiple-classifier of the model, then using the result passing into the softmax to predict the final prediction the gates in code split the matrix into multiple chunks and pass into the gates. Lecture 10P26: if the degree of the J is large, the information from J to I node is very small. Because the denominator is Djj Dii. the D^-0.5 A D^-0.5(connection) H(value of each neighbour, near features) W(parameter) Laplacian means to reduce the shape of the matrix, in the spectral matrix, the shape is quality large Each row and each column in matrix of Laplacian are zero ![Untitled](./post_img/COMP 5329/Untitled%202.png) the eigen matrix are used to reshape the original matrix, which similar to the PCA, focusing on the important part of the matrix Lecture 11the detected size of the boundary box many different. So, the resizing of the image is necessary for CNN. P16. The proposal may overlap, it makes the duplication of calculation. P17 Fast R-CNN: instead of using the image level input like P16, the fast way is using the features in CNN as input to the bounding box task. P20 But the problem of different sizes still exists, fast R-CNN uses the max pooling way to ensure the size of the output. Faster R-CNN: spp-net, improve at the extra pooling layer then fast R-CNN. In this model, the classification, detection, boundary box, etc tasks are all done by different CNNs. In other words, the nature of the faster here is replacing the original image object detection by the feature object detection. It reduces the computational resources. Mask R-CNN: deter the pixel in the image along to what label. RoIAlign is more accurate in the pooling layer, directly dividing the result evenly without considering the number, and using the distance of each point to decide the number of the results after the max pooling. excepted predict the xyhw, the dx,dy,dh,dw (difference of the xyhw) are also included in the prediction. Jargon called an anchor. Lecture 12high value in Dx, maximize the (1-D(G(z))) Lecture 13diffusion GAN: 输入为随机输入 f(theta) = Y Y 为图像 X 为随机输入 F（）为神经网络， 映射xy之间的转换关系，从正态分布到图像的分布（特殊的集合） 不用MSE的原因是 噪音和图像之前的关系没有有意义的关系，也就是梯度会没有， 并且只能生成看到过的图片， 不会生成没看见过的图片 生成式对抗模型：两个神经网络，生成式网络（生成假图）和分类器（检验真假） 生成式模型从分类起学会到如何生成真图 分类无法区分的时候，就训练完了 VAE: encoder the image, then decode it decode之后和原始的 计算loss 从参化 diffusion: 去燥模型，退热定律 X → XT.noisy(高斯) X → X+Theta → XT.noisy(高斯) X → … → X+Theta * n → XT.noisy(高斯) 每次加一点点噪音， 直到纯噪音 每次加的高斯分布的噪音 loss 为检测图片中的噪音数量 反过去，就是按照噪音去预测图片 diffusion只有一个NN，其他模型为多个","link":"/blog/2024/06/16/COMP%205329/"},{"title":"USYD - COMP 5046","text":"Lecture 1N-Gram LMs The 4 ways to deal with the unseen word sequence smoothing: discounting: ![Untitled](./post_img/COMP 5046/Untitled%201.png) Interpolation: using the multiple N-Gram probability ![Untitled](./post_img/COMP 5046/Untitled%202.png) Kneser-Ney smoothing: Lecture2Lecture3Lecture4Note the formula macro and micro F1 score — ass2 Not the find_best_socre initial number should be negative — ass2 directly using average will make some features vanish (+ and -), also the order is meaningless in slide, NER page 66 labels number * length * length means: each token in sequence is possible for start or end, that is length * length then, each span can be predicted as each label so, the output should be (labels * length * length) ![Untitled](./post_img/COMP 5046/Untitled%203.png) ![Untitled](./post_img/COMP 5046/Untitled%204.png) Lecture 5beam search in nature, greedy search is to find the local optimal solution in each step Lecture 6the label in current word from LSTM purely, B I O possibility(sum as 1) score = current label p * best (previous p * transfer p) it from score = current label p * best (i.e. DP * transfer model) DP refers to the optimal route in choice transfer model refers to the Markov model co reference dependency parsing Lecture 7Lecture 8disadvantages of self-attention problem: non-linear lacking order lacking resolve: feedforward layer additional position vector issue: the length of the position vector is fixed, not flexible enoughthe mask is for ignoring the future word in the training process, it lets the model know what is known in this step, and what is the prediction in this step. In math, put the infinite negative value for future words and dot the product in the current wordthe multiple layers of self-attention are used to build better representation of the word query: curve line key: embedding word value: passing into the weighted value Lecture 10data can from fineweb common craw Lecture 11ReviewThe content below is the missing slide week. parsing, 句法分析, identity the grammar structure by sub-phrases The span in the sentence called the phrase treebanks Method: Dependency Parsing / Grammar compute every possible dependency to find the best score Or, choose a way to get the best overall score co-reference","link":"/blog/2024/06/16/COMP%205046/"},{"title":"USYD - DATA 5207","text":"DATA 5207Lecture 2presenting data to non-expert (visualization) less technical knowledge making data engage convey the pattern Data Graphics 3 consideration what information want to communicate who is the target audience why design this feature relevant Lecture 3confounding factors: earning by height, may it occur by gender select the topic this weekend RMD template Lecture 4better R square, better job the model does. This means the better-fitting in model maximize the variables in the model not only use the technic thing to fit the data but adding the theoretical thing to increase the use in practice observational data can not make the causal inference (confounding factor included) model error random errors (precision limitation - sample number) systematic error (error in research design - non-sampling error) difference between observed and actual response, instrument, interviewer sample design error selection, frame explore dataset graphs variables model choice correlation plot all variables variable selection methods - stepwise, lasso, or Lecture 5limitation of the LR is assuming the relationship is linear logits? ordinal logistic regression (agree, very agree, etc) For the material in lab 5, the last image can be repainted as for each year, plot the importance of each variable (independent factor) into a single panel. Lecture 6fuzzyjoin is a function that similar operation in SQL Research Plan FormatFormatHide the R chunks, the template has the code to hide key feature should be identified why use the LR Literaturetheory from Literature hypothesis is for testing? is that the previous section provided literature: tells you, communicate the hypothesis you provide inform the things you need to do underpin the thing you want to explain may error in the literature section, falsify the idea Dataapi missing operation Limitationcan be deleted Lecture 7 Quiz weekdata can from consumer data social media AB testing (to decide the better version in different versions) for instance, the color, and size of the button may sent to users, and the amount they click to decide the better version census individuals include surveys web scraping Lecture 8survey system error - no random may younger people be more likely to respond to the phone (phone survey) - nonresponse bias The census is not like the survey, due to its not doing the data sample, according to the entire residents in the country random error refers to sampling Assignment-1 Economic: Q288, 50 (income) 1 Occupation: Q281, 282, 283 Education: Q275 https://d1wqtxts1xzle7.cloudfront.net/49101438/18.01.053.20160304-libre.pdf?1474797472=&response-content-disposition=inline%3B+filename%3DEffect_of_Education_on_Quality_of_Life_a.pdf&amp;Expires=1713509378&amp;Signature=bTvJ0cklHa83ixDEhUTW02gYB4KW0iex7Mx6etlJqBNha-f0l-gvirWcVjlpbtaXdn5SsFoSsWtjeay-18z5De6i3e2wRtZvtx5cuzyJe2RLJHKYPPXrkiEORhb9c35JK-WjFa7T8c8OIQj5RxD11Gj3W7wCsC3jJwVOewTDYwkVBKXC1-7BjpWcbOSrkZnazJwulzVzLIERo0l6iO51LIqFi6wY8TSiTTdFGhiHctf9bu2Y7IapgVAwDLKXbpYTdXd3c4nVMPqQryYQ5iOjKVEmcCdMQwn0HUGe837Dn38-7ttCIbNASUOgpjEGQEjmNlznMsOW9jG~X9VHjw__&amp;Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA https://www.sciencedirect.com/science/article/pii/S2214804314001153?via%3Dihub Societal Wellbeing: Q47 (health) Security: Q131-138, 52 Social capital, trust: Q57-61 https://link.springer.com/article/10.1007/s00148-007-0146-7 (neighbourhood only) PCA to combine the multiple variables into one feature Lecture 10cable library in R Lecture 11 - CausalityLecture 12 - Journalismdatasplash platform Final Projectthe plots and tables can be included in the report using the table to regression result (kable) function","link":"/blog/2024/06/16/DATA%205207/"},{"title":"Hutool","text":"Hutool工具类学习工具类，大杂烩 入门和安装 (hutool.cn) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161package com.example.jc_demo;import cn.hutool.core.convert.Convert;import cn.hutool.core.date.DateTime;import cn.hutool.core.date.DateUnit;import cn.hutool.core.date.DateUtil;import cn.hutool.core.date.Month;import cn.hutool.core.io.FileUtil;import cn.hutool.core.lang.Console;import cn.hutool.core.util.*;import jdk.nashorn.internal.runtime.regexp.joni.ast.StringNode;import lombok.extern.slf4j.Slf4j;import org.junit.jupiter.api.Test;import java.io.File;import java.util.Calendar;import java.util.Date;import java.util.List;import java.util.concurrent.TimeUnit;@Slf4jpublic class UtilsTest { @Test void Convert() { int a = 1; String str_a = Convert.toStr(a); log.info(String.valueOf(str_a instanceof String)); log.info(&quot;=========================================&quot;); String[] b = {&quot;1&quot;, &quot;2&quot;}; Integer[] integers = Convert.toIntArray(b); for (int i = 0; i &lt; integers.length; i++) { log.info(String.valueOf(integers[i] instanceof Integer)); } log.info(&quot;=========================================&quot;); String c = &quot;2022-10-10&quot;; log.info(String.valueOf(Convert.toDate(c) instanceof Date)); log.info(&quot;=========================================&quot;); Object[] d = {&quot;1&quot;, 2, &quot;牛&quot;, &quot;jc&quot;}; List&lt;?&gt; list = Convert.convert(List.class, d); list.forEach(e -&gt; { log.info(e.toString() + &quot;:&quot; + e.getClass().toString()); }); log.info(list.getClass().toString()); log.info(&quot;=========================================&quot;); String e = &quot;123456789&quot;; log.info(Convert.toSBC(e)); log.info(Convert.toDBC(Convert.toSBC(e))); log.info(&quot;=========================================&quot;); String f = &quot;STRING&quot;; log.info(Convert.toHex(f, CharsetUtil.CHARSET_UTF_8)); log.info(Convert.hexToStr(Convert.toHex(f, CharsetUtil.CHARSET_UTF_8), CharsetUtil.CHARSET_UTF_8)); log.info(&quot;=========================================&quot;); String g = &quot;字符串&quot;; String result = Convert.convertCharset(g, CharsetUtil.UTF_8, CharsetUtil.ISO_8859_1); String raw = Convert.convertCharset(result, CharsetUtil.ISO_8859_1, &quot;UTF-8&quot;); log.info(result); log.info(raw); log.info(&quot;=========================================&quot;); long l = 23466543; log.info(String.valueOf(Convert.convertTime(l, TimeUnit.MILLISECONDS, TimeUnit.MINUTES))); log.info(&quot;=========================================&quot;); double h = 1231.452; log.info(Convert.digitToChinese(h)); log.info(Convert.numberToWord(h)); log.info(Convert.numberToSimple(h)); log.info(Convert.numberToChinese(12341., false)); log.info(Convert.numberToChinese(1234.1, true)); log.info(String.valueOf(Convert.chineseToNumber(&quot;一万二千三百四十一&quot;))); log.info(&quot;=========================================&quot;); log.info(&quot;=========================================&quot;); } @Test void My_Date() { log.info(String.valueOf(Month.of(Calendar.JANUARY).getLastDay(false))); log.info(String.valueOf(Month.of(Calendar.JANUARY).getLastDay(true))); log.info(DateUtil.date().toString()); log.info(DateUtil.date().toDateStr()); log.info(DateUtil.date(System.currentTimeMillis()).toString()); log.info(DateUtil.now().toString()); log.info(DateUtil.today().toString()); log.info(DateUtil.parse(&quot;2022-10-10&quot;, &quot;yyyy-MM-dd&quot;).getClass().toString()); String date = &quot;2022-10-10&quot;; Date date1 = DateUtil.parse(date); log.info(DateUtil.format(date1, &quot;yyyy/MM/dd&quot;)); log.info(DateUtil.formatDate(date1)); log.info(DateUtil.formatDateTime(date1)); log.info(DateUtil.formatTime(date1)); log.info(String.valueOf(DateUtil.year(date1))); log.info(String.valueOf(DateUtil.month(date1))); } @Test void File_utils() { File[] ls = FileUtil.ls(&quot;C:\\\\Users&quot;); for (int i = 0; i &lt; ls.length; i++) { log.info(ls[i].getName()); } } @Test void StrUtils() { log.info(StrUtil.removeSuffix(&quot;a.jpg&quot;, &quot;.jpg&quot;)); log.info(StrUtil.removePrefix(&quot;a.jpg&quot;, &quot;a.&quot;)); String str = &quot;123abc&quot;; log.info(StrUtil.sub(str, 2, 4)); } @Test void IDCard() { String id1 = &quot;110101199003076413&quot;; log.info(String.valueOf(IdcardUtil.isValidCard(id1))); log.info(String.valueOf(IdcardUtil.getAgeByIdCard(id1))); log.info(String.valueOf(IdcardUtil.getBirthByIdCard(id1))); log.info(String.valueOf(IdcardUtil.getProvinceByIdCard(id1))); log.info(String.valueOf(IdcardUtil.getProvinceCodeByIdCard(id1))); } @Test void securityUtils() { log.info(DesensitizedUtil.idCardNum(&quot;110101199003076413&quot;, 4, 4)); log.info(DesensitizedUtil.mobilePhone(&quot;15157547799&quot;)); log.info(DesensitizedUtil.password(&quot;15157547799&quot;)); } @Test void CreditCode() { log.info(String.valueOf(CreditCodeUtil.isCreditCode(&quot;91310110666007217T&quot;))); log.info(CreditCodeUtil.randomCreditCode()); } @Test void outUtils() { Console.log(&quot;还能console 真不错&quot;); Console.log(&quot;还能{} 真不错&quot;, &quot;format&quot;); Console.error(&quot;还能{} 真不错&quot;, &quot;error&quot;); }}","link":"/blog/2023/12/18/Hutool%E5%B7%A5%E5%85%B7%E7%B1%BB%E5%AD%A6%E4%B9%A0/"},{"title":"Guava相关操作","text":"Guava相关操作Description(12条消息) Guava的基础功能与集合_鲲鹏飞九万里的博客-CSDN博客_guava 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189package com.example.jc_demo;import cn.hutool.core.date.DateUtil;import com.google.common.base.Preconditions;import com.google.common.collect.ImmutableSet;import com.google.common.collect.Ordering;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;import lombok.extern.slf4j.Slf4j;import org.junit.jupiter.api.Test;import java.util.*;@Slf4jpublic class GuavaTest { @Data @AllArgsConstructor @NoArgsConstructor class User { String name; } @Test public void my_Optional() { Optional&lt;Integer&gt; op = Optional.ofNullable(new Integer(123)); log.info(op.get().toString()); } @Test public void returnUser() { User u = new User(); u = null; // 如果不用ofNullable会有空指针异常 用ofNullable能够在get()的时候报出空元素异常 Optional&lt;User&gt; op = Optional.ofNullable(u); User u1 = op.get(); log.info(u1.toString()); } @Test public void orElse() { // ???防止空指针 备用值??? IFNULL??? Optional&lt;String&gt; op = Optional.of(&quot;aaa&quot;); log.info(String.valueOf(op.isPresent())); log.info(op.orElse(null)); } @Test public void isPresent() { Optional&lt;String&gt; op = Optional.of(&quot;2322&quot;); log.info(String.valueOf(op.isPresent())); Optional&lt;String&gt; op1 = Optional.ofNullable(null); log.info(String.valueOf(op1.isPresent())); } // @Test public void my_Preconditions() { int i = -1; int j = 10; String k = null; // Preconditions.checkArgument(i &gt; j, &quot;%s is not bigger than %s&quot;, i, j); // Preconditions.checkNotNull(k,&quot;k is null&quot;); // Preconditions.checkArgument(&quot;1&quot;.equals(&quot;2&quot;),&quot;1 is not equals 2&quot;); // int[] arr = new int[10]; // Preconditions.checkElementIndex(20,arr.length); } @Test public void myImmutableSet() { /** * 三种方式创建 只读数组 * 1.of * 2.builder * 3.copy * * 注意：不可放入null */ ImmutableSet&lt;String&gt; immutableSet = ImmutableSet.of(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;); immutableSet.forEach(e-&gt;{ log.info(e); }); // java.lang.UnsupportedOperationException 不允许操作数组， 只读 // immutableSet.add(&quot;d&quot;); ImmutableSet&lt;String&gt; immutableSet1 = ImmutableSet.&lt;String&gt;builder() .add(&quot;a&quot;) .add(&quot;b&quot;) .add(&quot;c&quot;) .build(); immutableSet1.forEach(e-&gt;{ log.info(e); }); // java.lang.UnsupportedOperationException 不允许操作数组， 只读 // immutableSet1.add(&quot;d&quot;); // ImmutableSet&lt;String&gt; immutableSet3 = ImmutableSet.copyOf(arrayList); } @Data @AllArgsConstructor @NoArgsConstructor private class Device { Date CreatTime; Date UpdateTime; } @Test public void my_Order() { Ordering ordering = new Ordering&lt;String&gt;() { // order by length @Override public int compare(String s, String t1) { return s.length() &gt; t1.length() ? new Integer(1) : new Integer(-1); } }; ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(); list.add(&quot;sadewf&quot;); list.add(&quot;sadewfsda&quot;); list.add(&quot;sadewfsdaasdfeao&quot;); list.add(&quot;aadewfsdaasdfea&quot;); list.add(&quot;zoad&quot;); list.add(&quot;zoadnas&quot;); list.add(&quot;doadn&quot;); list.add(&quot;doadnsadasda&quot;); list.add(&quot;zoadnasodnaosndaosd&quot;); //ascii ? Collections.sort(list); My_ForEach(list); Collections.sort(list, ordering); My_ForEach(list); Collections.reverse(list); My_ForEach(list); } @Test public void order2() { // 链式调用 从右往左调用，先orderBy XXX 将Null放最前或最后 对剩下的自然排序 Ordering&lt;Device&gt; ordering1 = Ordering.natural().nullsFirst().onResultOf((Device device) -&gt; device.CreatTime); Ordering&lt;Device&gt; ordering2 = Ordering.natural().nullsLast().onResultOf((Device device) -&gt; device.CreatTime); List&lt;Device&gt; list1 = new ArrayList&lt;&gt;(); list1.add(new Device(DateUtil.parse(&quot;2022-1-1&quot;, &quot;yyyy-MM-dd&quot;), null)); list1.add(new Device(null, null)); list1.add(new Device(DateUtil.parse(&quot;2022-1-8&quot;, &quot;yyyy-MM-dd&quot;), null)); list1.add(new Device(DateUtil.parse(&quot;2021-1-7&quot;, &quot;yyyy-MM-dd&quot;), null)); list1.add(new Device(DateUtil.parse(&quot;2022-5-1&quot;, &quot;yyyy-MM-dd&quot;), null)); list1.add(new Device(DateUtil.parse(&quot;2022-1-7&quot;, &quot;yyyy-MM-dd&quot;), null)); list1.add(new Device(DateUtil.parse(&quot;2022-3-1&quot;, &quot;yyyy-MM-dd&quot;), null)); list1.add(new Device(DateUtil.parse(&quot;2022-6-1&quot;, &quot;yyyy-MM-dd&quot;), null)); Collections.sort(list1, ordering2); My_ForEach(list1); } @Test public void isOrder() { List&lt;String&gt; list = new ArrayList&lt;&gt;(Arrays.asList(&quot;a&quot;, &quot;asd&quot;, &quot;b&quot;, &quot;asdve&quot;)); // 返回降序前两个 List&lt;String&gt; list1 = Ordering.natural().greatestOf(list, 2); // 返回升序后两个 List&lt;String&gt; list2 = Ordering.natural().leastOf(list, 2); My_ForEach(list1); My_ForEach(list2); } public void My_ForEach(List list) { if (list.size() &gt; 0) { list.forEach(e -&gt; { log.info(e.toString()); }); } else { log.error(&quot;空集合&quot;); } log.info(&quot;=======================================================&quot;); }}","link":"/blog/2023/12/18/Guava%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C/"},{"title":"SpringBoot","text":"SpringBoot分组校验 实体类中创建接口（为空，用于连接实体类以及接口） 在字段上对不同接口进行分别验证 Controller中对参数开启指定接口验证 1public Result updateDevice(@RequestBody @Validated(value = Device.UpdateDevice.class) Device device) throws ParseException { 123456789public interface InsertDevice {}public interface UpdateDevice {}@NotNull(message = &quot;设备ID不能为空&quot;, groups = {UpdateDevice.class})@ApiModelProperty(&quot;设备ID&quot;)private Integer id; 实体类使用引用类型由于java中的基本类型会有默认值，例如当某个类中存在private int age;字段时，创建这个类时，age会有默认值0.当使用age属性时，它总会有值。因此，在某些情况下，便无法使age为null.并且在动态SQL的部分，如果使用age != null 进行判断，结果总会为true,会导致很多隐藏的问题。 所以，在实体类中不要使用基本类型。基本类型包括 byte\\short\\int\\long\\float\\double\\char\\boolean. 结论:在mybatis中，不要使用基本类型，要使用引用类型。 统一处理权限返回值1234567891011@ControllerAdvicepublic class UnauthorizedAdvice { @ResponseBody @ExceptionHandler(AuthorizationException.class) public Result AuthorizationException(Exception ex) { // 登录了 但是操作权限没有 return new Result(ResultCode.UNAUTHENTICATED_OPERATION); }} @postConstruct 注解使用在方法上，表示该方法在实例化当前Bean后立刻执行该方法，再去实例化其他Bean 可以有多个@PostConstruct方法 做初始化工作 ResponseEntity.ok(execute)1234567@GetMapping(&quot;/lua&quot;) public ResponseEntity lua() { List&lt;String&gt; keys = Arrays.asList(&quot;testLua&quot;, &quot;hello lua&quot;); Boolean execute = stringRedisTemplate.execute(redisScript, keys, &quot;100&quot;,&quot;200&quot;); assert execute != null; return ResponseEntity.ok(execute); } 返回ok ClassPathResource1234567@Bean public DefaultRedisScript&lt;Boolean&gt; redisScript() { DefaultRedisScript&lt;Boolean&gt; redisScript = new DefaultRedisScript&lt;&gt;(); redisScript.setScriptSource(new ResourceScriptSource(new ClassPathResource(&quot;\\\\script\\\\firstLua.lua&quot;))); redisScript.setResultType(Boolean.class); return redisScript; } ClassPathResource直接在resources包下，路径打后面的就可以","link":"/blog/2022/10/27/SpringBoot/"},{"title":"JPA &amp; Java","text":"JAP @Entity @Table @Id @Query Sort sort = new Sort(Sort.Direction.DESC, “id”); —→ findAll(sort) Pageable pageable=PageRequest.of(0,5); 第一页 一页5条 extends JpaRepository&lt;T, ID&gt; List findByUsername(String username) 1234567891011121314interface PersonRepository extends Repository&lt;User, Long&gt; { // and 的查询关系 List&lt;User&gt; findByEmailAddressAndLastname(EmailAddress emailAddress, String lastname); // 包含 distinct 去重，or 的 sql 语法 List&lt;User&gt; findDistinctPeopleByLastnameOrFirstname(String lastname, String firstname); // 根据 lastname 字段查询忽略大小写 List&lt;User&gt; findByLastnameIgnoreCase(String lastname); // 根据 lastname 和 firstname 查询 equal 并且忽略大小写 List&lt;User&gt; findByLastnameAndFirstnameAllIgnoreCase(String lastname, String firstname); // 对查询结果根据 lastname 排序，正序 List&lt;User&gt; findByLastnameOrderByFirstnameAsc(String lastname); // 对查询结果根据 lastname 排序，倒序 List&lt;User&gt; findByLastnameOrderByFirstnameDesc(String lastname);} ![Untitled](D:\\hexo warehouse\\myblog\\source_posts\\Untitled-16690181602452.png) link: Spring Data JPA - Reference Documentation (16条消息) SpringDataJpa的使用 – 条件查询、排序查询、分页查询_十⑧的博客-CSDN博客_jpa 条件查询 stream list.stream().map(People::getAge) filter(i -&gt; i &gt; 5) count() collect(Collectors.toList() People::getAge tree code parent_code （queryProcessTree） 找父节点 遍历寻找子节点 递归 封装数据返回 queryLazyProcessTree 懒加载去除孩子节点数据（估计前端点击展开后继续往下查询） 找父节点 找所有ChildNode isleaf = ChildNode.getParentCode.equals(ParentsCode).count==0 ? false : true 封装返回 recursive sql 123456with recursive temp(id,username,pid,pname) AS ( SELECT k.id,k.username,k.pid,k.username from t_parent_kid k WHERE k.username='B' UNION ALL SELECT k.id,k.username,t.id,t.username from temp t,t_parent_kid k WHERE t.id=k.pid)SELECT * from temp ![Untitled 1](D:\\hexo warehouse\\myblog\\source_posts\\Untitled 1-16690181860235.png) ![Untitled 2](D:\\hexo warehouse\\myblog\\source_posts\\Untitled 2-16690181910378.png) union all / union uniall 整合两张表 上下连接，去重 uniall all 整合两张表 上下连接，列出全部","link":"/blog/2023/12/18/JPA%20&%20Java/"},{"title":"Pytorch Tutorial 1","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import torchimport numpy as npt1 = torch.tensor(4.)print(t1)print(t1.dtype)t2 = torch.tensor([1., 2, 3, 4])print(t2)print(t2.dtype)# in this case the all data will be transformed to same data type# [1., 2., 3., 4.]t3 = torch.tensor([1., 2, 3, 4])print(t3)print(t3.dtype)t4 = torch.tensor([[1, 2], [1., 4], [4, 3], [5, 6]])print(t4)print(t4.dtype)print(t1.shape)print(t2.shape)print(t3.shape)print(t4.shape)# ---x = torch.tensor(3., requires_grad=True)w = torch.tensor(4., requires_grad=True)b = torch.tensor(5., requires_grad=True)y = w * x + bprint(y)y.backward()print(x.grad)print(w.grad)print(b.grad)# convert numpy to torchx = np.array([[1, 2], [2, 4]])# use shared memory space, not copyy = torch.from_numpy(x)# copy datay = torch.tensor(x)print(y)print(y.dtype)# convert torch to numpyz = y.numpy()print(z)","link":"/blog/2023/12/20/Tutorial%201/"},{"title":"Pytorch Tutorial 2","text":"simple linear regression with auto gradient method in pytorch @ means inner dot .t() means transpose matrix .numel() means number of element in matrix with torch.no_grad() means code insider this block will not track gradients to save memory and computation time 123456789101112131415161718192021222324252627282930313233343536373839import torchimport numpy as npinputs = np.array([[0, 0, 3], [0, 1, 9], [1, 0, 8], [1, 1, 28]], dtype='float32')outputs = np.array([[0, 1], [9, 4], [7, 3], [6, 7]], dtype='float32')inputs = torch.from_numpy(inputs)outputs = torch.from_numpy(outputs)w = torch.randn(2, 3, requires_grad=True)b = torch.randn(2, requires_grad=True)# print(b)def model(x): # the b is the vector, when the matrix plus b, the b will be copy bunch of data to make it as the matrix return x @ w.t() + bdef mse(t1, t2): return torch.sum((t1 - t2) ** 2) / t1.numel()learning_rate = 1e-5for t in range(500): y_pred = model(inputs) loss = mse(y_pred, outputs) loss.backward() with torch.no_grad(): w -= learning_rate * w.grad b -= learning_rate * b.grad w.grad.zero_() b.grad.zero_() print(loss.item())","link":"/blog/2023/12/20/Tutorial%202/"},{"title":"USYD - INFO 5992","text":"INFO 5992Lecture 13 advantages and disadvantages of 5G wireless connections over 4G. More capacity for device connection in the meantime The higher transmission speed compared to the 4G The performance of latency shows the advantage The price of 5G IoT module almost doubled that 4G’s, showing more economic challenge, although showing the benefits on other areas. The coverage of 5G is weaker than 4G. Meanwhile, much time is still needed to establish an extensive area. Compatibility may become the upcoming problem in the future. Due to the out-of-date devices may not support the new standard(5G technology). Q1: Yes. The benefits(speed, network capacity and lower latency etc.) of 5G are highly suitable for lots of organizations, especially for IT-based organizations. The development of 5G is unstoppable, the cost, coverage and other weaknesses will be solved in the near future. Therefore, end users, organizations and governments will embrace the network evolution (i.e. 5G). Q2: The price will be lower. The cost of 5G network will be reduced, because of the more mature infrastructure and technology, which will be represented in the market price. The quantity of 5G users will increase gradually, which means that each 5G station cost will be separate for each user. It also will reduce the cost of 5G network use. Q3: Yes. The 5G breaks many physical limitations. For instance, time latency. In the practice of clinics, one of the biggest limitations of remote operation is a delay in the network. The on-time network(5G) can lower the limitation and enlarge the feasibility. Also, the high speed of 5G can realize the large-capacity meeting, its all owed to the 5G. Q4: No. In my point of view, the network 5G is faster than 4G, not fundamentally changing the way of the network, but the development of the network. Lecture 2 Diffusion of innovation Innovation development process Technology adoption lifecycle model Dominate Design Lecture 3 Disruptive innovation Innovator’s dilemma Lecture 4API business model API as product API promoting means making the main business more popular API enhancing means making the functionality better May pro but not en, but it can not be en no pro Lecture 5Types of Crowdsourcing P14 ![Untitled](./post_img/INFO 5992/Untitled.png) put information and data to the platform can compare with others’ solutions (10% better etc.) creative things basic level of human intelligence Lecture 6user innovation: the innovations from the user or customer (company, B2B), due to the unfulfilled requirement. Lecture 7customer pivoting solve the problem of the certain segment customers, and solve another problem of the same people business pivoting solve the different problems Lecture 8value proposition","link":"/blog/2024/06/15/INFO%205992/"},{"title":"Pytorch Tutorial 3","text":"simple linear regression with bulit in tools in pytorch generate prediction calculate the loss compute gradients of w and b adjust w and b reset gradients to zero these 5 steps also respect to the loop in the next function 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879import numpy as npimport torch.nn as nnimport torchfrom torch.utils.data import TensorDatasetfrom torch.utils.data import DataLoaderimport torch.nn.functional as F# temp, rainfall, humidity# inputs = torch.tensor(np.random.uniform(0, 120, size=(15, 3)))# the input and output here need to specify the dtype, otherwise, when torch generate the prediction,# it will encounter the problem of dtype is not matchinputs = torch.tensor(np.array( [[109.4144, 11.2775, 32.4521], [2.0002, 47.0248, 49.9469], [27.1528, 57.8907, 91.2076], [44.8227, 71.6239, 64.0752], [66.0968, 92.5966, 94.0775], [59.6257, 76.9701, 92.1656], [8.1551, 1.7426, 10.5297], [112.6036, 47.2793, 95.4221], [3.2212, 61.8274, 115.9187], [35.0351, 110.6133, 66.6992], [8.8387, 21.8008, 50.0480], [68.7698, 59.9815, 12.0230], [111.3881, 90.3050, 62.1327], [101.7462, 115.7447, 33.4925], [27.7659, 54.5803, 105.3599]], dtype='float32'))# apples, oranges# targets = torch.tensor(np.random.uniform(0, 50, size=(15, 2)))targets = torch.tensor(np.array( [[28.1090, 45.0061], [29.0839, 6.4205], [35.2633, 44.1196], [29.5371, 6.8457], [7.4298, 36.1434], [6.6296, 47.1809], [49.9750, 49.9321], [34.1796, 16.6732], [46.8875, 7.6084], [23.0442, 42.2229], [29.7401, 13.4199], [3.0854, 21.4550], [47.6801, 49.1518], [18.7320, 18.4418], [34.2725, 25.8721]], dtype='float32'))# print(inputs)# print(targets)# TensorDataset will creat the structure of pairing (input and target) accordinglytrain_ds = TensorDataset(inputs, targets)batch_size = 5train_dl = DataLoader(train_ds, batch_size, shuffle=True)# Each batch size is 5, and the data are shuffled# and is still can contain the pair of data, the structure won't be shuffled# for xb, yb in train_dl:# print(&quot;batch:&quot;)# print(xb)# print(yb)# specify the input and output feature numbermodel = nn.Linear(3, 2)# the weight and bias will be initialed automatically, and the parameter of requires_grad will be set as True# print(model.weight)# print(model.bias)# print(list(model.parameters()))# preds = model(inputs)# print(preds)loss_fn = F.mse_lossloss = loss_fn(model(inputs), targets)# print(loss)opt = torch.optim.SGD(model.parameters(), lr=1e-5)# 1 generate prediction# 2 calculate the loss# 3 compute gradients of w and b# 4 adjust w and b# 5 reset gradients to zero# these 5 steps also respect to the loop in the next functiondef fit(num_epochs, model, loss_fn, opt): # training interation for epoch in range(num_epochs): # batches in each interation for xb, yb in train_dl: pred = model(xb) loss = loss_fn(pred, yb) loss.backward() opt.step() opt.zero_grad() if (epoch+1) % 10 == 0: print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))fit(100, model, loss_fn, opt)","link":"/blog/2023/12/22/Tutorial%203/"},{"title":"Git学习","text":"GIT(12条消息) Git使用详细教程_youzhouliu的博客-CSDN博客_git使用 Git12345678# 回退上个版本git reset --soft HEAD^git reset --mixed HEAD^git reset --hard HEAD^# 回退上10个版本git reset --hard HEAD~10","link":"/blog/2023/12/18/git/"},{"title":"Pytorch Tutorial 4","text":"load dataset transform the data into tensor split the dataset into training, testing, validation datasets define the function of indices shuffle (the dataset are ordered, if missing apply the shuffle, the individual dataset may only contains one label) create sampler and loader customise the MnistModel function define loss_batch calculate loss in current batch define evaluate calculate average loss in batches define accuracy also called metric to shows the accuracy create fit function epoch loop train loop loss_batch — for train evaluate result print result call fit 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112from os import pathfrom random import randintimport torchimport torchvisionfrom torchvision.datasets import MNISTimport matplotlib.pyplot as pltimport numpy as npfrom torch.utils.data.dataloader import DataLoaderfrom torch.utils.data.sampler import SubsetRandomSamplerimport torch.nn as nnimport torch.nn.functional as F# transoforms used to transform the MNIST dataset into tensor in order to torch can work withimport torchvision.transforms as transforms# here the datasets in original format, can not be understood by torchdatasets = MNIST(root='./data', download=True)# print(len(datasets))test_dataset = MNIST(root='./data', train=False, transform=transforms.ToTensor())# print(len(test_dataset))# img, label = datasets[0]# plt.imshow(img, cmap='gray')# plt.show()# print(label)# here the dataset is already transformed into tensordataset = MNIST(root='./data', download=True, transform=transforms.ToTensor())# the shape here is 1,28,28, color, height, weight# img_tensor, label = dataset[0]# print(img_tensor.shape, label)# print(img_tensor[:, 10:15, 10:15])# print(torch.max(img_tensor), torch.min(img_tensor))# plt.imshow(img_tensor[0, 10:15, 10:15], cmap='gray')# plt.show()def split_indices(n, rate): # create number of validation set n_val = int(n * rate) # create shuffled index from 0-n, with no repeat idxs = np.random.permutation(n) # retuen (n_val,last) index and (first n_val) index # i.e. training index and validation index return idxs[n_val:], idxs[:n_val]train_indices, val_indices = split_indices(len(dataset), 0.2)# print(len(train_indices), len(val_indices))# the sampler here is randomly select the indices from list with number of batch_size# the reason for this is lower down the training time and computation# and utilize multiple epoch to train the model, if not, the training will deal with whole data set,# that will occupy too much memory space and make too much pressure to computational resources.# in this case, the training process will transfer to smaller chucksbatch_size = 100train_sampler = SubsetRandomSampler(train_indices)train_loder = DataLoader(dataset, batch_size, sampler=train_sampler)val_sampler = SubsetRandomSampler(val_indices)val_loder = DataLoader(dataset, batch_size, sampler=val_sampler)input_size = 28 * 28num_classes = 10# model = nn.Linear(input_size, num_classes)# print(model.weight.shape)# print(model.bias.shape)## print(model.weight)# print(model.bias)# for img, label in train_loder:# print(img.shape)# print(label)# # there is a error, the shape of image is 1*28*28, but the received input shape was set 784# # so, the customized model are needed.# print(model(img))# breakclass MnistModel(nn.Module): def __init__(self): super().__init__() # define the input and output for linear self.linear = nn.Linear(input_size, num_classes) def forward(self, xb): # reshape -1 here avoid the hard code, it will calculate the first dimension number xb = xb.reshape(-1, input_size) # pass the batch data to linear layer out = self.linear(xb) return outmodel = MnistModel()# the weight and bias are in the linear(model.linear.weight), instead of the model above(model.weight)# print(model.linear.weight.shape)# print(model.linear.bias.shape)## print(model.linear.weight)# print(model.linear.bias)def accuracy(l1, l2): return torch.sum(l1 == l2).item() / len(l2) Log plot presentation 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129# for img, label in train_loder:# the img pass in the model shape is 100,1,28,28# the output shape is 100,10# which reaches what we expected (represent the 0-9 digital number)# here the softmax can be introduced to show the possibility with each number correspondingly# possibility = e^y_i / sum(e^y_i)# outputs = model(img)# the second parameter here indicates the dim index need to be applied# so 0 means the column direction, and 1 for row direction for 2D matrix# probs = F.softmax(outputs, 1)# print(probs.shape)# so now the probs shape is 100,10, but each value each row represent possibility(0-1), and sum of each row is 1# print(outputs.shape)# print(outputs[0])# max_probs, predicted_labels = torch.max(probs, 1)# print(accuracy(predicted_labels, label))# now, we need to define the loss function# here the cross entropy is most suitable for logistic regression# i.e.# the true label 9 is represented vector of [0,0,0,0,0,0,0,0,0,1]# the predict vector [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9] for instance# and the cross entropy is -ln(y*y_pred) i.e. -ln(1*0.9) = 0.10, which is low# but, when the prediction is poor# the true label 1 is represented vector of [0,1,0,0,0,0,0,0,0,0]# the predict vector [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9] for instance# and the cross entropy is -ln(y*y_pred) i.e. -ln(1*0.2) = 1.6, which is high# in the cross entropy, we only consider the right label, and ignore the other, because their vector is 0# so when low possibility for the correct number the cross entropy(loss) is high, v.v# define the loss function for current batch# loss = F.cross_entropy(outputs, label)# the equation here is -e.pow(right prediction possibility)=loss# so the right possibility is e.pow(-loss)# learn_rate = 0.001# optimizer = torch.optim.SGD(model.parameters(), lr=learn_rate)# optimizer.step()# breakdef loss_batch(model, loss_func, xb, yb, opt=None, metric=None): preds = model(xb) loss = loss_func(preds, yb) if opt is not None: loss.backward() opt.step() opt.zero_grad() # metric is used for model evaluation metric_result = None if metric is not None: metric_result = metric(preds, yb) return loss.item(), len(xb), metric_resultdef evaluate(model, loss_func, valid_dl, metric=None): with torch.no_grad(): results = [loss_batch(model, loss_func, xb, yb, metric=metric) for xb, yb in valid_dl] # separate the lists loss, nums, metric = zip(*results) total = np.sum(nums) avg_loss = np.sum(np.multiply(loss, nums)) / total avg_metric = None if metric is not None: avg_metric = np.sum(np.multiply(metric, nums)) / total return avg_loss, total, avg_metricdef accuracy(output, label): _, preds = torch.max(output, dim=1) return torch.sum(label == preds).item() / len(preds)# avg_loss, total, val_acc = evaluate(model, F.cross_entropy, val_loder, metric=accuracy)# print(&quot;Loss: {:.4f}, total:{:.4f}, Accuracy: {:.4f}&quot;.format(avg_loss, total, val_acc))def fit(epochs, model, loss_fn, opt, train_dl, valid_dl, metric=None): for epoch in range(epochs): for xb, yb in train_dl: loss, _, _ = loss_batch(model, loss_fn, xb, yb, opt, metric=metric) result = evaluate(model, loss_fn, valid_dl, metric=metric) val_loss, total, val_metric = result if metric is None: print(&quot;Epoch [{}/{}], total:{:.4f}, Loss: {:.4f}&quot; .format(epoch + 1, epochs, total, val_loss, val_metric)) else: print(&quot;Epoch [{}/{}], total:{:.4f}, Loss: {:.4f}, {}: {:.4f}&quot; .format(epoch + 1, epochs, total, val_loss, metric.__name__, val_metric))model = MnistModel()# if path is not blankif path.exists('mnist-logistic.pth'): model.load_state_dict(torch.load('mnist-logistic.pth'))else: fit(5, model, F.cross_entropy, torch.optim.SGD(model.parameters(), lr=0.001), train_loder, val_loder, metric=accuracy) # it will save the weight and bias for this model torch.save(model.state_dict(), 'mnist-logistic.pth')# read the saved model into instance# model2 = MnistModel()# model2.load_state_dict(torch.load('mnist-logistic.pth'))# model2.state_dict()def prediction_img(img, model): xb = img.unsqueeze(0) yb = model(xb) _, preds = torch.max(yb, dim=1) return preds[0].item()for i in range(10): img, label = test_dataset[randint(0, len(test_dataset) - 1)] img_np = np.array(img) plt.imshow(img_np.squeeze(), cmap='gray') plt.show() print(prediction_img(img, model)) Question when import test_dataset missing the parameter of transform, made the validation section encounter the problem of img no squeeze parameter zip(*results), used for unpack the tuples, and pass into multiple instances avg_loss = np.sum(np.multiply(loss, nums)) / total the reason use multiply here is for last batch number, is might not equals to previous number","link":"/blog/2023/12/21/Tutorial%204/"},{"title":"任务调度框架","text":"学习quartz任务调度框架介绍Quartz 是什么？一文带你入坑 - 知乎 (zhihu.com) 其他框架 —— 3千字带你搞懂XXL-JOB任务调度平台 (baidu.com) xxl job (大众点评 许雪里) elasticjob （依托zookeeper） STEP 导入maven依赖 创建自定义Job类 实现Job 在execute中进行任务编写 创建任务调度工程工厂 创建定时器（startNow() or startAt(Date date)） schedule.start() 123456789101112131415161718192021222324252627package com.jcDemo.quartz;import lombok.extern.slf4j.Slf4j;import org.quartz.Job;import org.quartz.JobExecutionContext;import org.quartz.JobExecutionException;import java.time.LocalDateTime;import java.time.format.DateTimeFormatter;/** *@author:gao_quansui *@user:ASUS*@date:2022/9/29- 14:44 *@projectName:jc_demo*/@Slf4jpublic class TestJob implements Job { private static intindex= 1; @Override public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException { String data = LocalDateTime.now().format(DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss&quot;));log.info(&quot;第{}次执行 Timed Task, current time ：{}&quot;,index++, data); }} 123456789101112131415161718192021222324252627282930313233343536373839package com.jcDemo.controller.quartz;import com.jcDemo.quartz.TestJob;import lombok.extern.slf4j.Slf4j;import org.quartz.*;import org.quartz.impl.StdSchedulerFactory;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;/** *@author:gao_quansui *@user:ASUS*@date:2022/9/29- 14:47 *@projectName:jc_demo*/@Slf4j@RestControllerpublic class QuartzController { @RequestMapping(&quot;/quartz/test&quot;) public void test() throws SchedulerException { Scheduler scheduler = StdSchedulerFactory.getDefaultScheduler(); // 定义任务调度实例, 并与TestJob绑定 JobDetail job = JobBuilder.newJob(TestJob.class) .withIdentity(&quot;testJob&quot;, &quot;testJobGroup&quot;) .build(); // 定义触发器, 会马上执行一次, 接着5秒执行一次, 共十次 Trigger trigger = TriggerBuilder.newTrigger() .withIdentity(&quot;testTrigger&quot;, &quot;testTriggerGroup&quot;) .startNow() .withSchedule(SimpleScheduleBuilder.repeatSecondlyForTotalCount(10, 1)) .build(); // 使用触发器调度任务的执行 scheduler.scheduleJob(job, trigger); // 开启任务 scheduler.start(); }}","link":"/blog/2023/12/18/%E5%AD%A6%E4%B9%A0quartz%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E6%A1%86%E6%9E%B6/"},{"title":"学习rabbitMQ","text":"学习rabbitMQ介绍：(12条消息) windows环境下安装RabbitMQ（超详细）_luckySnow-julyo的博客-CSDN博客_windows安装rabbitmq 其他框架Kafka、RabbitMQ、RocketMQ 全方位对比 - 龘人上天 - 博客园 (cnblogs.com) 整合步骤： 下载rabbitMQ，解压 maven依赖 添加config类（生产者消费者应该不同项目） 启动rabbitMQ Rabbitmq的启动和停止 - .未央 - 博客园 (cnblogs.com) 访问 http://localhost:15672 usernname: guest password: guest 其他 模拟器 RabbitMQ Simulator (tryrabbitmq.com) shift连线，连不上换方向 123456789&lt;!--rabbitmq--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374package com.jcDemo.config;import org.springframework.amqp.core.*;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * @author: gao_quansui * @user:ASUS * @date:2022/9/27 - 14:15 * @projectName:jc_demo */@Configurationpublic class DirectRabbitMQConfig { // 创建队列 @Bean public Queue TestDirectQueue() { return new Queue(&quot;DirectQueue&quot;, true); } @Bean public Queue TopicQueue() { return new Queue(&quot;TopicQueue&quot;, true); } @Bean Queue FanoutQueue1(){ return new Queue(&quot;Fanout.Queue1&quot;); } @Bean Queue FanoutQueue2(){ return new Queue(&quot;Fanout.Queue2&quot;); } // 创建交换机 @Bean DirectExchange DirectExchange() { return new DirectExchange(&quot;DirectExchange&quot;, true, false); } @Bean TopicExchange TopicExchange(){ return new TopicExchange(&quot;TopicExchange&quot;,true,false); } @Bean FanoutExchange FanoutExchange(){ return new FanoutExchange(&quot;FanoutExchange&quot;,true,false); } // 建立连接绑定 // 直连为一个连接，即一对一 @Bean Binding bindingDirect() { return BindingBuilder.bind(TestDirectQueue()).to(DirectExchange()).with(&quot;DirectRoutingKey&quot;); } // 队列可以绑定多个生产者 @Bean Binding bindingTopic(){ return BindingBuilder.bind(TopicQueue()).to(TopicExchange()).with(&quot;TopicRoutingKey.#&quot;); // 匹配多个路由，使得消费者可以收到多个生产者的消息 } // 交换机可以绑定多个队列（广播模式） （没有路由key） @Bean Binding bindingFanout1(){ return BindingBuilder.bind(FanoutQueue1()).to(FanoutExchange()); } @Bean Binding bindingFanout2(){ return BindingBuilder.bind(FanoutQueue2()).to(FanoutExchange()); }} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081package com.jcDemo.controller.mq;import org.springframework.amqp.rabbit.core.RabbitTemplate;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;import java.time.LocalDateTime;import java.time.format.DateTimeFormatter;import java.util.HashMap;import java.util.Map;import java.util.UUID;/** * @author: gao_quansui * @user:ASUS * @date:2022/9/27 - 14:18 * @projectName:jc_demo */@RestControllerpublic class MQTest { //使用RabbitTemplate,这提供了接收/发送等等方法 @Autowired RabbitTemplate rabbitTemplate; @GetMapping(&quot;/sendDirectMessage&quot;) public String sendDirectMessage() { String messageId = String.valueOf(UUID.randomUUID()); String messageData = &quot;direct producer message, hello!&quot;; String createTime = LocalDateTime.now().format(DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss&quot;)); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;messageId&quot;, messageId); map.put(&quot;messageData&quot;, messageData); map.put(&quot;createTime&quot;, createTime); //将消息携带绑定键值 rabbitTemplate.convertAndSend(&quot;DirectExchange&quot;, &quot;DirectRoutingKey&quot;, map); return &quot;ok&quot;; } @GetMapping(&quot;/sendTopicMessage1&quot;) public String sendTopicMessage1() { String messageId = String.valueOf(UUID.randomUUID()); String messageData = &quot;topic producer1 message, hello!&quot;; String createTime = LocalDateTime.now().format(DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss&quot;)); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;messageId&quot;, messageId); map.put(&quot;messageData&quot;, messageData); map.put(&quot;createTime&quot;, createTime); //将消息携带绑定键值 rabbitTemplate.convertAndSend(&quot;TopicExchange&quot;, &quot;TopicRoutingKey.test1&quot;, map); return &quot;ok&quot;; } @GetMapping(&quot;/sendTopicMessage2&quot;) public String sendTopicMessage2() { String messageId = String.valueOf(UUID.randomUUID()); String messageData = &quot;topic producer2 message, hello!&quot;; String createTime = LocalDateTime.now().format(DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss&quot;)); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;messageId&quot;, messageId); map.put(&quot;messageData&quot;, messageData); map.put(&quot;createTime&quot;, createTime); //将消息携带绑定键值 rabbitTemplate.convertAndSend(&quot;TopicExchange&quot;, &quot;TopicRoutingKey.test2&quot;, map); return &quot;ok&quot;; } @GetMapping(&quot;/sendFanoutMessage&quot;) public String sendFanoutMessage() { String messageId = String.valueOf(UUID.randomUUID()); String messageData = &quot;fanout producer message, hello!&quot;; String createTime = LocalDateTime.now().format(DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss&quot;)); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;messageId&quot;, messageId); map.put(&quot;messageData&quot;, messageData); map.put(&quot;createTime&quot;, createTime); rabbitTemplate.convertAndSend(&quot;FanoutExchange&quot;,&quot;&quot;,map); return &quot;ok&quot;; }} 消费者-Direct12345678910@Slf4j@Component@RabbitListener(queues = &quot;DirectQueue&quot;)public class ConsumerDirect { @RabbitHandler public void process(Map testMessage) { log.info(&quot;DirectQueue的消费者收到消息{}&quot;,testMessage.toString()); }} 消费者-Topic123456789101112131415161718192021222324252627282930package com.rabbit_consumer.mq;import lombok.extern.slf4j.Slf4j;import org.springframework.amqp.rabbit.annotation.Queue;import org.springframework.amqp.rabbit.annotation.RabbitHandler;import org.springframework.amqp.rabbit.annotation.RabbitListener;import org.springframework.amqp.rabbit.annotation.RabbitListeners;import org.springframework.stereotype.Component;import javax.naming.Binding;import java.util.Map;/** * @author: gao_quansui * @user:ASUS * @date:2022/10/9 - 9:59 * @projectName:rabbit_consumer */@Slf4j@Component@RabbitListener(queues = &quot;TopicQueue&quot;)// 该队列对应的生产者有两个， 能够收到两个生产者的消息，不同于直连的一一对应关系public class ConsumerTopic { @RabbitHandler public void process(Map map){ log.info(&quot;TopicQueue received:{}&quot;,map.toString()); }} 消费者-Fanout1234567891011121314151617181920212223242526272829303132package com.rabbit_consumer.mq;import lombok.extern.slf4j.Slf4j;import org.springframework.amqp.rabbit.annotation.RabbitHandler;import org.springframework.amqp.rabbit.annotation.RabbitListener;import org.springframework.stereotype.Component;import java.util.Map;/** * @author: gao_quansui * @user:ASUS * @date:2022/10/9 - 13:45 * @projectName:rabbit_consumer */@Slf4j@Componentpublic class ConsumerFanout { @RabbitListener(queues = &quot;Fanout.Queue1&quot;) // @RabbitHandler public void process1(Map map) { log.info(&quot;Consumer1 receive from FanoutQueue:{}&quot;, map); } @RabbitListener(queues = &quot;Fanout.Queue2&quot;) // @RabbitHandler public void process(Map map){ log.info(&quot;Consumer2 receive from FanoutQueue:{}&quot;,map); }} 总结 三种模式 Direct 直连 一一对应 Topic 主题连接 利用*，# 进行匹配 一个交换机对应多个生产者 （）只能向后匹配一个单词 即 a. → a.a(可以) a.a.a(不可以) （#）只能向后匹配多个单词 即 a.* → a.a(可以) a.a.a(可以) Fanout 广播模式 一个交换机分发到多个队列，队列对应到相应的消费者 疑问： 能否实现一个生产者，一个交换机，一个队列，分发多个消费者？","link":"/blog/2023/12/18/%E5%AD%A6%E4%B9%A0rabbitMQ/"},{"title":"Shiro","text":"shiro实现权限其他框架：sprintSecurity（还未研究，据说类似） 配置步骤： 导入maven 添加ShiroConfig 创建UserRealm 注意： 在过滤器创建的时候是 LinkedHashMap 千万注意， 不然通配符不会匹配，会被覆盖掉 过滤器创建时可设置未授权跳转页面，不适用于分离项目 过滤工厂创建的时候可以放入自定义拦截器，用于项目自己的业务 可以在subject.login()之前，通过对session设置来修改登录过期时间 核心： Subject 获取当前对象 token可用username，password生成 可使用Md5Hash进行加密 在调用login后通过捕获异常来区别不同的登录情况 12345678910&lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-core&lt;/artifactId&gt; &lt;version&gt;1.7.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-spring&lt;/artifactId&gt; &lt;version&gt;1.4.0&lt;/version&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384package com.jcDemo.shiro;import com.jcDemo.interceptor.MyFormAuthenticationFilter;import org.apache.shiro.mgt.DefaultSecurityManager;import org.apache.shiro.mgt.SecurityManager;import org.apache.shiro.spring.security.interceptor.AuthorizationAttributeSourceAdvisor;import org.apache.shiro.spring.web.ShiroFilterFactoryBean;import org.apache.shiro.web.mgt.DefaultWebSecurityManager;import org.springframework.aop.framework.autoproxy.DefaultAdvisorAutoProxyCreator;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import javax.servlet.Filter;import java.util.HashMap;import java.util.LinkedHashMap;import java.util.Map;/** *@author:gao_quansui *@user:ASUS*@date:2022/9/21- 10:57 *@projectName:jc_demo*/@Configurationpublic class ShiroConfig { @Bean public UserRealm userRealm() { return new UserRealm(); } @Bean(name = &quot;filterShiroFilterRegistrationBean&quot;) public ShiroFilterFactoryBean getShiroFilterFactoryBean(@Qualifier(&quot;SecurityManager&quot;) DefaultWebSecurityManager defaultWebSecurityManager) { //1.创建过滤工厂 ShiroFilterFactoryBean bean = new ShiroFilterFactoryBean(); Map&lt;String, Filter&gt; filters = new LinkedHashMap&lt;&gt;(); filters.put(&quot;MyFormAuthenticationFilter&quot;, new MyFormAuthenticationFilter()); bean.setFilters(filters); //2.设置安全管理器 bean.setSecurityManager(defaultWebSecurityManager); //3.配置未授权跳转页面// bean.setLoginUrl(&quot;/test&quot;);// bean.setLoginUrl(null); //4.设置filter Map&lt;String, String&gt; filterMap = new LinkedHashMap&lt;&gt;(); filterMap.put(&quot;/api/user/login&quot;, &quot;anon&quot;); filterMap.put(&quot;/api/**&quot;, &quot;MyFormAuthenticationFilter&quot;); bean.setFilterChainDefinitionMap(filterMap); return bean; } @Bean(name = &quot;SecurityManager&quot;) public DefaultWebSecurityManager getDefaultWebSecurityManager(@Qualifier(&quot;userRealm&quot;) UserRealm userRealm) { DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager(); securityManager.setRealm(userRealm); return securityManager; } //开启shiro注解 @Bean public AuthorizationAttributeSourceAdvisor authorizationAttributeSourceAdvisor(SecurityManager securityManager) { AuthorizationAttributeSourceAdvisor advisor = new AuthorizationAttributeSourceAdvisor(); advisor.setSecurityManager(securityManager); return advisor; } //开启aop注解支持 @Bean public DefaultAdvisorAutoProxyCreator defaultAdvisorAutoProxyCreator() { DefaultAdvisorAutoProxyCreator defaultAAP = new DefaultAdvisorAutoProxyCreator(); defaultAAP.setProxyTargetClass(true); return defaultAAP; }} 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485package com.jcDemo.shiro;import com.jcDemo.entity.entities.User;import com.jcDemo.entity.vo.UidUsernameName;import com.jcDemo.service.user.RoleService;import com.jcDemo.service.user.UserService;import lombok.extern.slf4j.Slf4j;import org.apache.shiro.SecurityUtils;import org.apache.shiro.authc.*;import org.apache.shiro.authz.AuthorizationInfo;import org.apache.shiro.authz.SimpleAuthorizationInfo;import org.apache.shiro.realm.AuthorizingRealm;import org.apache.shiro.subject.PrincipalCollection;import org.apache.shiro.subject.Subject;import org.springframework.beans.factory.annotation.Autowired;import java.util.List;/** *@author:gao_quansui *@user:ASUS*@date:2022/9/21- 10:07 *@projectName:jc_demo*/@Slf4jpublic class UserRealm extends AuthorizingRealm { @Autowired UserService userService; @Autowired RoleService roleService; //授权 @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principalCollection) {log.info(&quot;执行====================授权&quot;); SimpleAuthorizationInfo info = new SimpleAuthorizationInfo();// Object data = roleService.getUserRoleById(1).getData();// info.addStringPermission(&quot;&quot;); Subject subject = SecurityUtils.getSubject(); User user = (User) subject.getPrincipal(); //下面方法传上来的user对象 //获取当前用户的权限数组 List&lt;UidUsernameName&gt; uidUsernameName = (List&lt;UidUsernameName&gt;) roleService.getUserRoleById(user.getId()); //遍历添加权限 uidUsernameName.forEach(e -&gt; { info.addStringPermission(e.getRoleName()); log.info(&quot;username:{}-------roleName:{}&quot;, e.getUsername(), e.getRoleName()); }); return info; } //认证 @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException { UsernamePasswordToken userToken = (UsernamePasswordToken) token; User user = userService.getUserByName(userToken.getUsername()); if (user == null) { return null; } log.info(&quot;认证&quot;); Subject subject = SecurityUtils.getSubject();// subject.isPermitted(&quot;123&quot;);// subject.hasRole(&quot;authc&quot;);// if(!userToken.getUsername().equals(user.getUsername())){// return null; //会在controller中捕获// }// return new SimpleAuthenticationInfo(user, user.getPassword(), &quot;&quot;); //验证密码// return null; }} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package com.jcDemo.interceptor;import com.alibaba.fastjson.JSON;import com.alibaba.fastjson.JSONObject;import com.jcDemo.entity.res.Result;import com.jcDemo.entity.res.ResultCode;import lombok.extern.slf4j.Slf4j;import org.apache.shiro.web.filter.authc.FormAuthenticationFilter;import org.apache.shiro.web.servlet.ShiroHttpServletRequest;import org.springframework.util.StringUtils;import javax.servlet.ServletRequest;import javax.servlet.ServletResponse;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;import java.io.PrintWriter;/** *@author:gao_quansui *@user:ASUS*@date:2022/9/28- 10:07 *@projectName:jc_demo*/@Slf4jpublic class MyFormAuthenticationFilter extends FormAuthenticationFilter { @Override protected boolean onAccessDenied(ServletRequest request, ServletResponse response) throws Exception {log.info(&quot;被shiro拦截啦=================================&quot;); PrintWriter out = null; try { HttpServletResponse res = (HttpServletResponse) response; response.setCharacterEncoding(&quot;UTF-8&quot;); response.setContentType(&quot;application/json; charset=utf-8&quot;); out = response.getWriter(); if (res.getStatus() == HttpServletResponse.SC_UNAUTHORIZED) { out.println(JSON.toJSONString(new Result(ResultCode.UNAUTHORISE))); } else { if (StringUtils.isEmpty(((ShiroHttpServletRequest) request).getHeader(&quot;Authorization&quot;))) {log.info(&quot;未登录&quot;); out.write(JSONObject.toJSONString(new Result(ResultCode.UNAUTHENTICATED, &quot;&quot;))); } else {log.info(&quot;session已过期&quot;); out.write(JSONObject.toJSONString(new Result(ResultCode.EXPIREDSESSION, &quot;&quot;))); } } } catch (IOException e) {log.info(&quot;session异常&quot;); } finally { if (out != null) { out.close(); } } return Boolean.FALSE; } @Override protected boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue) { return super.isAccessAllowed(request, response, mappedValue); }}","link":"/blog/2023/12/18/shiro%E5%AE%9E%E7%8E%B0%E6%9D%83%E9%99%90/"},{"title":"shiro结合ehcache实现缓存","text":"Description为解决每次调用接口都执行shiro授权操作，影响效率，因此引入缓存概念 STEP 导入依赖 配置ehcache-shieo.xml文件 ShiroConfig类中添加相关Bean EhCacheManager DefaultWebSecurityManager（设置缓存管理器，即a） UserRealm中启用验证，名字为xml文件中的 启动类开启缓存 1234567891011121314151617181920&lt;!-- 开启 cache 缓存 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-cache&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- ehcache 缓存 --&gt;&lt;!-- https://mvnrepository.com/artifact/org.apache.shiro/shiro-ehcache --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-ehcache&lt;/artifactId&gt; &lt;version&gt;1.10.0&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/net.sf.ehcache/ehcache-core --&gt;&lt;dependency&gt; &lt;groupId&gt;net.sf.ehcache&lt;/groupId&gt; &lt;artifactId&gt;ehcache-core&lt;/artifactId&gt; &lt;version&gt;2.6.11&lt;/version&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;ehcache name=&quot;es&quot;&gt; &lt;!-- 缓存对象存放路径 java.io.tmpdir：默认的临时文件存放路径。 user.home：用户的主目录。 user.dir：用户的当前工作目录，即当前程序所对应的工作路径。 其它通过命令行指定的系统属性，如“java –DdiskStore.path=D:\\\\abc ……”。 --&gt; &lt;diskStore path=&quot;java.io.tmpdir&quot;/&gt; &lt;!-- name:缓存名称。 maxElementsOnDisk：硬盘最大缓存个数。0表示不限制 maxEntriesLocalHeap：指定允许在内存中存放元素的最大数量，0表示不限制。 maxBytesLocalDisk：指定当前缓存能够使用的硬盘的最大字节数，其值可以是数字加单位，单位可以是K、M或者G，不区分大小写， 如：30G。当在CacheManager级别指定了该属性后，Cache级别也可以用百分比来表示， 如：60%，表示最多使用CacheManager级别指定硬盘容量的60%。该属性也可以在运行期指定。当指定了该属性后会隐式的使当前Cache的overflowToDisk为true。 maxEntriesInCache：指定缓存中允许存放元素的最大数量。这个属性也可以在运行期动态修改。但是这个属性只对Terracotta分布式缓存有用。 maxBytesLocalHeap：指定当前缓存能够使用的堆内存的最大字节数，其值的设置规则跟maxBytesLocalDisk是一样的。 maxBytesLocalOffHeap：指定当前Cache允许使用的非堆内存的最大字节数。当指定了该属性后，会使当前Cache的overflowToOffHeap的值变为true， 如果我们需要关闭overflowToOffHeap，那么我们需要显示的指定overflowToOffHeap的值为false。 overflowToDisk:boolean类型，默认为false。当内存里面的缓存已经达到预设的上限时是否允许将按驱除策略驱除的元素保存在硬盘上，默认是LRU（最近最少使用）。 当指定为false的时候表示缓存信息不会保存到磁盘上，只会保存在内存中。 该属性现在已经废弃，推荐使用cache元素的子元素persistence来代替，如：&lt;persistence strategy=”localTempSwap”/&gt;。 diskSpoolBufferSizeMB：当往磁盘上写入缓存信息时缓冲区的大小，单位是MB，默认是30。 overflowToOffHeap：boolean类型，默认为false。表示是否允许Cache使用非堆内存进行存储，非堆内存是不受Java GC影响的。该属性只对企业版Ehcache有用。 copyOnRead：当指定该属性为true时，我们在从Cache中读数据时取到的是Cache中对应元素的一个copy副本，而不是对应的一个引用。默认为false。 copyOnWrite：当指定该属性为true时，我们在往Cache中写入数据时用的是原对象的一个copy副本，而不是对应的一个引用。默认为false。 timeToIdleSeconds：单位是秒，表示一个元素所允许闲置的最大时间，也就是说一个元素在不被请求的情况下允许在缓存中待的最大时间。默认是0，表示不限制。 timeToLiveSeconds：单位是秒，表示无论一个元素闲置与否，其允许在Cache中存在的最大时间。默认是0，表示不限制。 eternal：boolean类型，表示是否永恒，默认为false。如果设为true，将忽略timeToIdleSeconds和timeToLiveSeconds，Cache内的元素永远都不会过期，也就不会因为元素的过期而被清除了。 diskExpiryThreadIntervalSeconds ：单位是秒，表示多久检查元素是否过期的线程多久运行一次，默认是120秒。 clearOnFlush：boolean类型。表示在调用Cache的flush方法时是否要清空MemoryStore。默认为true。 diskPersistent：是否缓存虚拟机重启期数据 Whether the disk store persists between restarts of the Virtual Machine. The default value is false. maxElementsInMemory:缓存最大数目 memoryStoreEvictionPolicy：当达到maxElementsInMemory限制时，Ehcache将会根据指定的策略去清理内存。默认策略是LRU（最近最少使用）。你可以设置为FIFO（先进先出）或是LFU（较少使用）。 memoryStoreEvictionPolicy: Ehcache的三种清空策略; FIFO，first in first out，这个是大家最熟的，先进先出。 LFU， Less Frequently Used，就是上面例子中使用的策略，直白一点就是讲一直以来最少被使用的。如上面所讲，缓存的元素有一个hit属性，hit值最小的将会被清出缓存。 LRU，Least Recently Used，最近最少使用的，缓存的元素有一个时间戳，当缓存容量满了，而又需要腾出地方来缓存新的元素的时候，那么现有缓存元素中时间戳离当前时间最远的元素将被清出缓存。 --&gt; &lt;defaultCache maxElementsInMemory=&quot;10000&quot; eternal=&quot;false&quot; timeToIdleSeconds=&quot;0&quot; timeToLiveSeconds=&quot;0&quot; overflowToDisk=&quot;false&quot; diskPersistent=&quot;false&quot; diskExpiryThreadIntervalSeconds=&quot;120&quot; /&gt; &lt;!-- 授权缓存 --&gt; &lt;cache name=&quot;authorizationCache&quot; maxEntriesLocalHeap=&quot;2000&quot; eternal=&quot;false&quot; timeToIdleSeconds=&quot;0&quot; timeToLiveSeconds=&quot;0&quot; overflowToDisk=&quot;false&quot; statistics=&quot;true&quot;&gt; &lt;/cache&gt; &lt;!-- 认证缓存 --&gt; &lt;cache name=&quot;authenticationCache&quot; maxEntriesLocalHeap=&quot;2000&quot; eternal=&quot;false&quot; timeToIdleSeconds=&quot;0&quot; timeToLiveSeconds=&quot;0&quot; overflowToDisk=&quot;false&quot; statistics=&quot;true&quot;&gt; &lt;/cache&gt;&lt;/ehcache&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113package com.jc_demo.shiro;import com.jc_demo.entity.entities.User;import com.jc_demo.interceptor.MyFormAuthenticationFilter;import org.apache.shiro.cache.ehcache.EhCacheManager;import org.apache.shiro.mgt.SecurityManager;import org.apache.shiro.spring.security.interceptor.AuthorizationAttributeSourceAdvisor;import org.apache.shiro.spring.web.ShiroFilterFactoryBean;import org.apache.shiro.web.mgt.DefaultWebSecurityManager;import org.springframework.aop.framework.autoproxy.DefaultAdvisorAutoProxyCreator;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import javax.servlet.Filter;import java.util.LinkedHashMap;import java.util.Map;/** * @author: gao_quansui * @user:ASUS * @date:2022/9/21 - 10:57 * @projectName:jc_demo */@Configurationpublic class ShiroConfig { @Bean public UserRealm userRealm() { UserRealm ur= new UserRealm(); // 告诉realm,使用credentialsMatcher加密算法类来验证密文 // ur.setCredentialsMatcher(hashedCredentialsMatcher()); /* 开启支持缓存，需要配置如下几个参数 */ ur.setCachingEnabled(true); // 启用身份验证缓存，即缓存AuthenticationInfo信息，默认false ur.setAuthenticationCachingEnabled(true); // 缓存AuthenticationInfo信息的缓存名称 在 ehcache-shiro.xml 中有对应缓存的配置 ur.setAuthenticationCacheName(&quot;authenticationCache&quot;); // 启用授权缓存，即缓存AuthorizationInfo信息，默认false ur.setAuthorizationCachingEnabled(true); // 缓存AuthorizationInfo 信息的缓存名称 在 ehcache-shiro.xml 中有对应缓存的配置 ur.setAuthorizationCacheName(&quot;authorizationCache&quot;); return ur; } @Bean(name = &quot;filterShiroFilterRegistrationBean&quot;) public ShiroFilterFactoryBean getShiroFilterFactoryBean(@Qualifier(&quot;SecurityManager&quot;) DefaultWebSecurityManager defaultWebSecurityManager) { // 1.创建过滤工厂 ShiroFilterFactoryBean bean = new ShiroFilterFactoryBean(); Map&lt;String, Filter&gt; filters = new LinkedHashMap&lt;&gt;(); filters.put(&quot;MyFormAuthenticationFilter&quot;, new MyFormAuthenticationFilter()); bean.setFilters(filters); // 2.设置安全管理器 bean.setSecurityManager(defaultWebSecurityManager); // 3.配置未授权跳转页面 // bean.setLoginUrl(&quot;/test&quot;); // 4.设置filter Map&lt;String, String&gt; filterMap = new LinkedHashMap&lt;&gt;(); filterMap.put(&quot;/api/user/login&quot;, &quot;anon&quot;); // filterMap.put(&quot;/api/user/role/**&quot;, &quot;authc&quot;); filterMap.put(&quot;/api/**&quot;, &quot;MyFormAuthenticationFilter&quot;); bean.setFilterChainDefinitionMap(filterMap); return bean; } @Bean(name = &quot;SecurityManager&quot;) public DefaultWebSecurityManager getDefaultWebSecurityManager(@Qualifier(&quot;userRealm&quot;) UserRealm userRealm) { DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager(); // 将 CookieRememberMeManager 注入到 SecurityManager 中，否则不会生效 // securityManager.setRememberMeManager(rememberMeManager()); // 将 sessionManager 注入到 SecurityManager 中，否则不会生效 // securityManager.setSessionManager(sessionManager()); // 将 EhCacheManager 注入到 SecurityManager 中，否则不会生效 securityManager.setCacheManager(ehCacheManager()); securityManager.setRealm(userRealm); return securityManager; } // 开启shiro注解 @Bean public AuthorizationAttributeSourceAdvisor authorizationAttributeSourceAdvisor(SecurityManager securityManager) { AuthorizationAttributeSourceAdvisor advisor = new AuthorizationAttributeSourceAdvisor(); advisor.setSecurityManager(securityManager); return advisor; } // 开启aop注解支持 @Bean public DefaultAdvisorAutoProxyCreator defaultAdvisorAutoProxyCreator() { DefaultAdvisorAutoProxyCreator defaultAAP = new DefaultAdvisorAutoProxyCreator(); defaultAAP.setProxyTargetClass(true); return defaultAAP; } // shiro 缓存 @Bean public EhCacheManager ehCacheManager(){ EhCacheManager cacheManager = new EhCacheManager(); cacheManager.setCacheManagerConfigFile(&quot;classpath:\\\\shiro\\\\ehcache-shiro.xml&quot;); return cacheManager; }} 1234567891011121314151617181920package com.jc_demo;import org.mybatis.spring.annotation.MapperScan;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cache.annotation.EnableCaching;import springfox.documentation.oas.annotations.EnableOpenApi;@EnableCaching// 开启缓存 shiro权限认证@EnableOpenApi@SpringBootApplication@MapperScan(&quot;com.jc_demo.mapper&quot;)public class JcDemoApplication { public static void main(String[] args) { SpringApplication.run(JcDemoApplication.class, args); }}","link":"/blog/2022/10/20/shiro%E7%BB%93%E5%90%88ehcache%E5%AE%9E%E7%8E%B0%E7%BC%93%E5%AD%98/"},{"title":"学习并发","text":"学习并发 创建线程的方式 继承Thread类创建 已经继承的类无法使用 123456789101112public class ExtendThread extends Thread {}@Testvoid test1() { ExtendThread extendThread = new ExtendThread(); log.info(&quot;threadId:{}&quot;, extendThread.getId()); log.info(&quot;threadName:{}&quot;, extendThread.getName()); log.info(&quot;threadState:{}&quot;, extendThread.getState()); log.info(&quot;threadPriority:{}&quot;, extendThread.getPriority());} 实现Runnable接口 可以使用匿名对象来进行实现，减少代码 1234567@Testvoid test4(){ Thread thread = new Thread(()-&gt;{ System.out.println(&quot;lambda+匿名对象类&quot;); },&quot;threadName&quot;); thread.start();} 利用Callable和FutureTask创建 异步？ 通过线程池创建 减少线程创建、销毁时间 123456789101112131415161718192021222324252627282930313233private static ExecutorServicepool= Executors.newFixedThreadPool(3);static class DemoThread implements Runnable{ @SneakyThrows @Override public void run() { for (int i = 0; i &lt; 10; i++) { log.info(&quot;execute times of runnable thread:{}&quot;,i); } }}static class ReturnableTask implements Callable&lt;Long&gt;{ public Long call() throws Exception{ long startTime = System.currentTimeMillis(); for (int i = 0; i &lt;10; i++) { log.info(&quot;execute times of Callable Thread:{}&quot;,i); } long used = System.currentTimeMillis() - startTime; return used; }}@Testpublic void test5() throws ExecutionException, InterruptedException { pool.execute(new DemoThread()); // 无返回值 Future future =pool.submit(new ReturnableTask()); Long result = (Long) future.get(); log.info(&quot;异步的结果为：{}&quot;,result); // 有返回值} 线程池 创建线程池 固定数量线程池 ExecutorService pool = Executors.newFixedThreadPool(3); 缓存线程池 ExecutorService pool = Executors.newCachedThreadPool(); 定时执行线程池 ScheduledExecutorService pool = Executors.newScheduledThreadPool(2); 线程池标准创建方式 12345678910111213141516171819202122public class ThreadPoolExecutor{ // 核心线程数，即使线程空闲（Idle），也不会回收； int corePoolSize; // 线程数的上限； int maximumPoolSize; // 线程最大空闲（Idle）时长 long keepAliveTime; //单位？ TimeUnit unit; // 任务的排队队列 BlockingQueue&lt;Runnable&gt; workQueue; // 新线程的产生方式 ThreadFactory threadFactory; // 拒绝策略 RejectedExecutionHandler handler;} 向线程池提交的方式 execute 只能接收Runnable类型的参数 没有返回值 不利于异常捕获 submit 能接受Runnable 和 Callable 有返回值 可以通过返回的Future（异步执行实例）对象来进行异常捕获 线程工厂 123456789@Testpublic void test9() { ExecutorService my_pool = Executors.newFixedThreadPool(2, new My_thread_factory()); for (int i = 0; i &lt; 5; i++) { my_pool.execute(new Task()); }pool.shutdown();} 线程安全 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package com.example.jc_demo.ThreadTest;import lombok.extern.slf4j.Slf4j;import org.junit.jupiter.api.Test;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;/** *@AUTHOR:gao_quansui *@USER:ASUS *@DATE:2022/10/13 - 15:43 *@PROJECT_NAME:jc_demo */@Slf4jpublic class ThreadSecurity { private static intcount= 0; class increaseVariable implements Runnable { @Override public void run() { plus(); } } // synchronized 关键字设置同步方法 为粗粒度 整个方法都保护为一个线程执行 // 相反 synchronized 代码块为细粒度 只保证代码块中的被一个线程执行 public synchronized void plus() {count++; } @Test public void test1() throws InterruptedException { ExecutorService pool = Executors.newFixedThreadPool(30); for (int i = 0; i &lt; 10000; i++) { pool.submit(new increaseVariable()); } Thread.sleep(500); pool.shutdown();log.info(String.valueOf(count)); }}","link":"/blog/2023/12/18/%E5%AD%A6%E4%B9%A0%E5%B9%B6%E5%8F%91/"},{"title":"整合swagger","text":"整合swaggerSwagger简介(12条消息) swagger使用教程——快速使用swagger_其实不会敲代码的博客-CSDN博客_swagger使用 Step maven依赖 配置SwaggerConfig（作者，项目名，邮件等） 启动后访问路径Swagger UI 使用 实体类中 @ApiModel类描述 @ApiModelProperty类中字段描述 控制器中 @Api控制器描述 @ApiOperation接口描述 12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt;&lt;/dependency&gt; 1234567891011121314151617181920212223242526272829303132package com.jcDemo.config;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import springfox.documentation.builders.ApiInfoBuilder;import springfox.documentation.builders.PathSelectors;import springfox.documentation.builders.RequestHandlerSelectors;import springfox.documentation.service.ApiInfo;import springfox.documentation.service.Contact;import springfox.documentation.spi.DocumentationType;import springfox.documentation.spring.web.plugins.Docket;import springfox.documentation.swagger2.annotations.EnableSwagger2;/** *@author:gao_quansui *@user:ASUS*@date:2022/9/22- 10:08 *@projectName:jc_demo*/@Configurationpublic class SwaggerConfig { @Bean public Docket docket() { return new Docket(DocumentationType.OAS_30).apiInfo( new ApiInfoBuilder() .contact(new Contact(&quot;gqs&quot;, &quot;&quot;, &quot;&quot;)) .title(&quot;JC_Demo&quot;) .build() ); }}","link":"/blog/2023/12/18/%E6%95%B4%E5%90%88swagger/"},{"title":"整合redis缓存","text":"整合redis缓存分布式锁的实现和解析(12条消息) 分布式锁之Redis实现_kuan_sun的博客-CSDN博客_redis锁的实现 整合步骤： 下载redis，解压，修改配置文件（redis.windows.conf） 导入redis启动依赖 创建redis配置类 （主要是对于kv的序列化和反序列化） 启动redis-server.exe （redis服务）（同时也可以通过指定配置文件进行启动—集群） 启动redis-cli.exe (操作客户端) 注意： HashMap不能设置过期时间！！！ 使用device:No_001:Name 的方式来存放K 在存放value（对象）时 需要导入FastJson来进行操作 redis操作都在redisTemplate中，有很多操作，需要熟悉 引入缓存可能导致的问题（目前能想到的） 在修改后，需要对缓存进行操作，不然缓存中的数据有误 在修改时判断是否有缓存 ？ 有：改缓存，利用缓存来修改持久层的（可以慢慢操作，在缓存失效之前操作完） 没有：修改持久层的，存缓存（有修改，一定马上会用到） 删除两边都得删 新增时添加缓存（新增也一定马上会用到） 查找时：如果缓存有，是否需要更新过期时间？ 分页需要做缓存吗，怎么做？ 可以改进的方向： redis集群 锁 利用redis中String来做 setnx device:NO_001_Lock 1 ex time 0则再用，重试请求；1进行业务操作 设置过期时间，避免设置锁后宕机死锁 时间需合适 太短：还没操作完就释放了 太长：已经操作完了 还锁着 解决：线程守护 设置一定时长 例设置10s 8s时判断是否还在执行？ 延长 ： 不延长 12345&lt;!-- redis依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package com.jcDemo.config;import com.alibaba.fastjson2.support.spring.data.redis.FastJsonRedisSerializer;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.connection.RedisConnectionFactory;import org.springframework.data.redis.core.*;import org.springframework.data.redis.listener.RedisMessageListenerContainer;import org.springframework.data.redis.serializer.GenericToStringSerializer;import org.springframework.data.redis.serializer.StringRedisSerializer;/** *@author:gao_quansui *@user:ASUS*@date:2022/9/28- 13:41 *@projectName:jc_demo*/@Configurationpublic class RedisConfig { @Bean public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory factory) { FastJsonRedisSerializer&lt;Object&gt; objectFastJsonRedisSerializer = new FastJsonRedisSerializer&lt;&gt;(Object.class); StringRedisSerializer stringRedisSerializer = new StringRedisSerializer(); // 自定义的RedisTemplate RedisTemplate&lt;String, Object&gt; redisTemplate = new RedisTemplate&lt;&gt;(); // 设置key的序列化方法 redisTemplate.setKeySerializer(new StringRedisSerializer()); // 核心的设置 1.2.36版本自动提供 redisTemplate.setValueSerializer(objectFastJsonRedisSerializer); // 对hash的序列化操作设置 redisTemplate.setHashKeySerializer(stringRedisSerializer); redisTemplate.setHashValueSerializer(objectFastJsonRedisSerializer); // 注册到工程类 redisTemplate.setConnectionFactory(factory); return redisTemplate; } @Bean public ValueOperations&lt;String, Object&gt; valueOperations(RedisTemplate&lt;String, Object&gt; redisTemplate) { return redisTemplate.opsForValue(); } @Bean public HashOperations&lt;String, String, Object&gt; hashOperations(RedisTemplate&lt;String, Object&gt; redisTemplate) { return redisTemplate.opsForHash(); } @Bean public ListOperations&lt;String, Object&gt; listOperations(RedisTemplate&lt;String, Object&gt; redisTemplate) { return redisTemplate.opsForList(); } @Bean public SetOperations&lt;String, Object&gt; setOperations(RedisTemplate&lt;String, Object&gt; redisTemplate) { return redisTemplate.opsForSet(); } @Bean public ZSetOperations&lt;String, Object&gt; zSetOperations(RedisTemplate&lt;String, Object&gt; redisTemplate) { return redisTemplate.opsForZSet(); }} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152package com.jcDemo.controller;import com.alibaba.fastjson.JSON;import com.alibaba.fastjson.JSONObject;import com.github.pagehelper.Page;import com.github.pagehelper.PageHelper;import com.jcDemo.commom.CommonException;import com.jcDemo.entity.entities.Device;import com.jcDemo.entity.res.PageResult;import com.jcDemo.entity.res.Result;import com.jcDemo.entity.res.ResultCode;import com.jcDemo.service.device.DeviceService;import io.swagger.annotations.Api;import io.swagger.annotations.ApiModel;import io.swagger.annotations.ApiOperation;import lombok.extern.slf4j.Slf4j;import lombok.var;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.redis.connection.RedisConnection;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.*;import javax.annotation.Resource;import java.text.ParseException;import java.util.List;import java.util.concurrent.TimeUnit;/** *@author:gao_quansui *@user:ASUS*@date:2022/9/23- 10:51 *@projectName:jc_demo*/@Slf4j@Api(tags = &quot;设备管理&quot;)@RestController@RequestMapping(&quot;/api/device&quot;)public class DeviceController { @Autowired DeviceService deviceService; @Resource RedisTemplate redisTemplate; @ApiOperation(&quot;查找所有设备&quot;) @GetMapping(&quot;/getDevices&quot;) public Result getDevices(@RequestParam(defaultValue = &quot;1&quot;) int pageNum, @RequestParam(defaultValue = &quot;10&quot;) int pageSize) { PageResult pr = null; try { Page page = PageHelper.startPage(pageNum, pageSize); List&lt;Device&gt; devices = deviceService.getDevices(); pr = new PageResult(page.getTotal(), devices);log.info(&quot;pageNum:{},pageSize:{}&quot;, pageNum, pageSize); } catch (CommonException e) { e.printStackTrace(); return new Result(ResultCode.EMPTY); } return new Result(ResultCode.SUCCESS, pr); } //设备编号查询 @ApiOperation(&quot;查找设备ByNo&quot;) @GetMapping(&quot;/getDeviceByNo/{no}&quot;) public Result getDeviceByNo(@PathVariable(&quot;no&quot;) String no) throws CommonException { Device device = null; try { if (redisTemplate.hasKey(&quot;devices:&quot; + no)) {log.info(&quot;重置时间-&gt;devices:{}&quot;, no); redisTemplate.expire(&quot;devices:&quot; + no, 300, TimeUnit.SECONDS);log.info(&quot;从redis取出来的devices:{}&quot;, no); device = JSON.parseObject(String.valueOf(redisTemplate.opsForValue().get(&quot;devices:&quot; + no)), Device.class); } else {log.info(&quot;从mysql取出来的{}&quot;, no); //mysql没有抛异常 下面捕获返回空 device = deviceService.getDeviceByNo(no); //取出来存入缓存 redisTemplate.opsForValue().set(&quot;devices:&quot; + no, JSON.toJSONString(device), 300, TimeUnit.SECONDS); } return new Result(ResultCode.SUCCESS, device); } catch (CommonException e) { e.printStackTrace(); return new Result(ResultCode.EMPTY); } } //查询 @ApiOperation(&quot;头部查找&quot;) @GetMapping(&quot;/searchDevice&quot;) public Result searchDevice(@RequestBody Device device) { List&lt;Device&gt; devices; try { devices = deviceService.searchDevice(device); return new Result(ResultCode.SUCCESS, devices); } catch (CommonException e) { e.printStackTrace(); return new Result(ResultCode.EMPTY); } } @ApiOperation(&quot;更新设备&quot;) @PostMapping(&quot;/updateDevice&quot;) public Result updateDevice(@RequestBody Device device) throws ParseException { if (deviceService.updateDevice(device) == 1) { //更新成功后判断是否有缓存 有就换 if (redisTemplate.hasKey(&quot;devices:&quot; + device.getDeviceNo())) { Boolean delete = redisTemplate.delete(&quot;devices:&quot; + device.getDeviceNo()); if (delete) { redisTemplate.opsForValue().set(&quot;devices:&quot; + device.getDeviceNo(), JSON.toJSONString(device), 300, TimeUnit.SECONDS); } else {log.warn(&quot;缓存更新失败，请检查！&quot;); } } else { redisTemplate.opsForValue().set(&quot;devices:&quot; + device.getDeviceNo(), JSON.toJSONString(device), 300, TimeUnit.SECONDS); } return new Result(ResultCode.SUCCESS); } else { return new Result(ResultCode.ERROR); } } @ApiOperation(&quot;删除设备&quot;) @DeleteMapping(&quot;/delete/{no}&quot;) public Result deleteDeviceById(@PathVariable(&quot;no&quot;) String no) { if (deviceService.deleteDeviceByNo(no) == 1) { //删除成功后处理redis if (redisTemplate.delete(&quot;devices:&quot; + no)) {log.warn(&quot;缓存删除成功&quot;); } else { //缓存删除失败 or 从select里面取的数据，没有进redis 直接删除也会打印loglog.warn(&quot;缓存删除失败，请检查！&quot;); } return new Result(ResultCode.SUCCESS); } else { return new Result(ResultCode.ERROR); } } @ApiOperation(&quot;新增设备&quot;) @PostMapping(&quot;/insert&quot;) public Result insertDevice(@RequestBody Device device) throws ParseException { if (deviceService.insertDevice(device) == 1) { redisTemplate.opsForValue().set(&quot;devices:&quot; + device.getDeviceNo(), JSON.toJSONString(device), 300, TimeUnit.SECONDS); return new Result(ResultCode.SUCCESS); } else { return new Result(ResultCode.ERROR); } }}","link":"/blog/2023/12/18/%E6%95%B4%E5%90%88redis%E7%BC%93%E5%AD%98/"},{"title":"Pytorch Tutorial 5","text":"The reason use the NN is inner kernel of logistic regression is still linear, to avoid the linear relationship, the NN can use activation function, for instance ReLU. In this case, we use ReLu as our activation function to predict the image, and it can be found that the accuracy is far better than LR, shows more abilities. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186from os import path, mkdirfrom random import randintimport torchimport numpy as npimport torchvisionfrom matplotlib import pyplot as pltfrom torchvision.datasets import MNISTfrom torchvision.transforms import ToTensorfrom torch.utils.data.sampler import SubsetRandomSamplerfrom torch.utils.data.dataloader import DataLoaderimport torch.nn.functional as Fimport torch.nn as nndataset = MNIST(root=&quot;./data&quot;, download=True, transform=ToTensor())test_dataset = MNIST(root='./data', train=False, transform=ToTensor())def split_indices(n, rate): # create number of validation set n_val = int(n * rate) # create shuffled index from 0-n, with no repeat idxs = np.random.permutation(n) # retuen (n_val,last) index and (first n_val) index # i.e. training index and validation index return idxs[n_val:], idxs[:n_val]train_indices, val_indices = split_indices(len(dataset), 0.2)batch_size = 100train_sampler = SubsetRandomSampler(train_indices)train_loder = DataLoader(dataset, batch_size, sampler=train_sampler)val_sampler = SubsetRandomSampler(val_indices)val_loder = DataLoader(dataset, batch_size, sampler=val_sampler)input_size = 28 * 28num_classes = 10class MnistModel(nn.Module): def __init__(self, in_size, hidden_size, out_size): super().__init__() self.linear1 = nn.Linear(in_size, hidden_size) self.linear2 = nn.Linear(hidden_size, out_size) def forward(self, xb): # flatten xb = xb.view(xb.size(0), -1) # xb = xb.reshape(xb.size(0), -1) return self.linear2(F.relu(self.linear1(xb)))# for t in model.parameters():# print(t.shape)# for img, labels in train_loder:# outputs = model(img)# loss = F.cross_entropy(outputs, labels)# breakdef get_device(): if torch.cuda.is_available(): return torch.device('cuda') else: return torch.device('cpu')def to_device(data, device): if isinstance(data, (list, tuple)): return [to_device(x, device) for x in data] return data.to(device, non_blocking=True)# for img, label in train_loder:# print(img.shape)# img = to_device(img, device)# print(img.device)# breakclass DeviceDataLoder(): def __init__(self, dl, device): self.dl = dl self.device = device def __iter__(self): # lazy load here # instead of load data into device each time, instead, load each batch for b in self.dl: yield to_device(b, self.device) def __len__(self): return len(self.dl)# use DeviceDataLoader as warppertrain_dl = DeviceDataLoder(train_loder, get_device())valid_dl = DeviceDataLoder(val_loder, get_device())def loss_batch(model, loss_func, xb, yb, opt=None, metric=None): preds = model(xb) loss = loss_func(preds, yb) if opt is not None: loss.backward() opt.step() opt.zero_grad() metric_result = None if metric is not None: metric_result = metric(preds, yb) return loss.item(), len(xb), metric_resultdef evaluate(model, loss_func, valid_dl, metric=None): with torch.no_grad(): results = [loss_batch(model, loss_func, xb, yb, metric=metric) for xb, yb in valid_dl] # separate the lists loss, nums, metric = zip(*results) total = np.sum(nums) avg_loss = np.sum(np.multiply(loss, nums)) / total avg_metric = None if metric is not None: avg_metric = np.sum(np.multiply(metric, nums)) / total return avg_loss, total, avg_metricdef fit(epochs, lr, model, loss_func, train_dl, valid_dl, opt_fn=None, metric=None): if opt_fn is None: opt_fn = torch.optim.SGD opt = opt_fn(model.parameters(), lr=lr) loss_history = [] metric_history = [] for epoch in range(epochs): for xb, yb in train_dl: loss_batch(model, loss_func, xb, yb, opt) result = evaluate(model, loss_func, valid_dl, metric) val_loss, total, val_metric = result loss_history.append(val_loss) metric_history.append(val_metric) if metric is not None: print(f'Epoch [{epoch + 1}/{epochs}], Loss: {val_loss:.4f}, Metric: {val_metric:.4f}') else: print(f'Epoch [{epoch + 1}/{epochs}], Loss: {val_loss:.4f}') return loss_history, metric_historydef accuracy(output, label): _, preds = torch.max(output, dim=1) return torch.sum(label == preds).item() / len(preds)model = MnistModel(input_size, 32, num_classes)to_device(model, get_device())if path.exists('./tutorial5/mnist-logistic.pth'): model.load_state_dict(torch.load('./tutorial5/mnist-logistic.pth'))else: loss_history, metric_history = fit(5, 0.5, model, F.cross_entropy, train_dl, valid_dl, opt_fn=torch.optim.SGD, metric=accuracy) # it will save the weight and bias for this model # new dir mkdir('./tutorial5') torch.save(model.state_dict(), './tutorial5/mnist-logistic.pth')def prediction_img(img, model): xb = img.unsqueeze(0) yb = model(xb) _, preds = torch.max(yb, dim=1) return preds[0].item()for i in range(10): img, label = test_dataset[randint(0, len(test_dataset) - 1)] img_np = np.array(img) plt.imshow(img_np.squeeze(), cmap='gray') plt.show() print(prediction_img(img, model))","link":"/blog/2023/12/22/Tutorial%205/"}],"tags":[{"name":"Pytorch","slug":"Pytorch","link":"/blog/tags/Pytorch/"},{"name":"Machine Learning","slug":"Machine-Learning","link":"/blog/tags/Machine-Learning/"},{"name":"Deep Learning","slug":"Deep-Learning","link":"/blog/tags/Deep-Learning/"},{"name":"NLP","slug":"NLP","link":"/blog/tags/NLP/"},{"name":"Natural Language Processing","slug":"Natural-Language-Processing","link":"/blog/tags/Natural-Language-Processing/"},{"name":"Data Analyse","slug":"Data-Analyse","link":"/blog/tags/Data-Analyse/"},{"name":"Social Science","slug":"Social-Science","link":"/blog/tags/Social-Science/"},{"name":"R","slug":"R","link":"/blog/tags/R/"},{"name":"Linear Regression","slug":"Linear-Regression","link":"/blog/tags/Linear-Regression/"},{"name":"Tools","slug":"Tools","link":"/blog/tags/Tools/"},{"name":"Java","slug":"Java","link":"/blog/tags/Java/"},{"name":"SpringBoot","slug":"SpringBoot","link":"/blog/tags/SpringBoot/"},{"name":"JPA","slug":"JPA","link":"/blog/tags/JPA/"},{"name":"Python","slug":"Python","link":"/blog/tags/Python/"},{"name":"IT Innovation","slug":"IT-Innovation","link":"/blog/tags/IT-Innovation/"},{"name":"Startups","slug":"Startups","link":"/blog/tags/Startups/"},{"name":"GIT","slug":"GIT","link":"/blog/tags/GIT/"},{"name":"Schedule","slug":"Schedule","link":"/blog/tags/Schedule/"},{"name":"MQ","slug":"MQ","link":"/blog/tags/MQ/"},{"name":"Security","slug":"Security","link":"/blog/tags/Security/"},{"name":"Shiro","slug":"Shiro","link":"/blog/tags/Shiro/"},{"name":"Cache","slug":"Cache","link":"/blog/tags/Cache/"},{"name":"Thread","slug":"Thread","link":"/blog/tags/Thread/"},{"name":"Swagger","slug":"Swagger","link":"/blog/tags/Swagger/"},{"name":"Redis","slug":"Redis","link":"/blog/tags/Redis/"}],"categories":[{"name":"USYD - Lecture","slug":"USYD-Lecture","link":"/blog/categories/USYD-Lecture/"},{"name":"Internship","slug":"Internship","link":"/blog/categories/Internship/"},{"name":"Pytorch Introduction","slug":"Pytorch-Introduction","link":"/blog/categories/Pytorch-Introduction/"}],"pages":[]}